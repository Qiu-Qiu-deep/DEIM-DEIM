# FMA

## 1. 动机

### 现有方法的问题：

#### **变压器（Transformer）的计算瓶颈：**
- **多头自注意力机制（MHSA）**虽然能有效建模全局连接性和长距离依赖关系，但其计算复杂度是**二次方级别**的（O(N²)），随着输入空间尺寸的增加，计算成本和内存占用呈指数增长[1][3]
- 在超分辨率任务中处理大分辨率图像时，MHSA 会导致巨大的内存资源占用，限制了在移动设备上的实际部署[3]

#### **卷积神经网络（ConvNet）的局限性：**
- 传统卷积感知**局部感受野有限**，即使通过堆叠多层也难以有效捕捉全局依赖关系[3]
- 小尺寸卷积核的不足感受野探索限制了学习能力，影响重建质量[3]

#### **现有大核注意力（LKA）方法的不足：**
- 虽然一些工作（如 VAN）通过大核卷积实现了线性复杂度的注意力机制，但在**全局上下文学习**方面仍然不如 MHSA 有效[24]
- 大核卷积容易激活所有特征值，缺乏足够的判别能力，影响特征聚合效果[24]

### 提出模块的目的：

FMA 旨在设计一种**类似 MHSA 但计算和参数效率更高**的注意力算子，能够：
1. 在**更低的计算成本**（线性复杂度）下实现长期和短期依赖性建模
2. 有效捕捉**全局感受野**，即使在网络早期层也能建模全局上下文
3. 平衡**局部和全局**特征学习能力[3][4]

---

## 2. 模块工作原理和核心思想

### 核心思想基于三个关键观察：

1. **线性注意力机制**：值特征与大核卷积特征之间的逐元素乘法可以有效唤起全局空间注意力，但只涉及**线性计算复杂度**（而非 MHSA 的二次复杂度）[4]

2. **傅里叶域的全局特性**：频域中的傅里叶频谱能够捕捉**整个图像的全局感受野**，即使在网络早期层也能实现全局建模[4]

3. **窗口注意力设计**：借鉴 Swin Transformer 的窗口注意力方案，能够同时进行**局部和全局感知**的特征学习[4]

---

### 详细工作流程：

FMA 通过三个主要步骤实现区域频率-空间调制：

#### **步骤一：空间-频谱特征交互（Spatial-Fourier Interaction）**

```
输入：X ∈ R^(H×W×C)
↓
层归一化：LN(X)
↓
空间 → 频谱：Ā = RealFFT(LN(X))
结果：Ā ∈ R^(H×W/2×2C)
↓
频谱卷积：Â = Conv1×1(Ā)
结果：Â ∈ R^(H×W/2×2C)
↓
频谱 → 空间：A = IRealFFT(Â)
结果：A ∈ R^(H×W×C)
```

**技术细节：**

- **2D 离散实数快速傅里叶变换（RealFFT）**：
  - 将归一化后的空间特征投影到频谱域
  - 利用傅里叶变换的全局特性，能够在频域中操作整个图像级别的频谱[6][9]

- **1×1 卷积在频域**：
  - 在频谱域中学习频率信息
  - 根据频谱卷积定理，这等效于在空间域进行全局卷积操作[9]

- **逆傅里叶变换（IRealFFT）**：
  - 将学习后的频率特征重新投影回空间域
  - 得到包含全局上下文信息的特征 A[9]

**核心优势：**
- 通过"RealFFT-Conv-IRealFFT"操作，能够有效操作整个图像级别的频谱，在早期层就能捕捉全局感受野[6][9]
- 相比大核卷积，傅里叶变换能更有效地去除输入特征的冗余，产生稀疏的激活图[24]

#### **步骤二：区域调制（Regional Modulation）**

**并行值编码：**
```
值特征：V = Conv1×1(LN(X))
结果：V ∈ R^(H×W×C)
```

**多头分组与块分割：**
```
重塑 A 和 V：
A, V → R^(Head × C_Head × L)
其中 L = H × W

块分割（Patch Partition）：
将 A 和 V 分割成 N 个 p×p 的不重叠块
[A₁, A₂, ..., Aₙ] 和 [V₁, V₂, ..., Vₙ]
每个块：R^(Head × C_Head × L/p²)
```

**局部线性注意力计算：**
```
对每个块 n：
  局部注意力 = Aₙ ⊗ Vₙ  (逐元素乘法)

全局聚合：
LA = Softmax(Concat_{1≤n≤N}(Aₙ ⊗ Vₙ)) + CPE(X)
```

**技术细节：**

- **块分割策略**：
  - 将特征图划分为 N 个不重叠的 p×p 局部区域
  - 每个块独立进行注意力计算，实现局部建模[9][10]

- **逐元素乘法**：
  - 在每个局部块内，通过 A 和 V 的逐元素乘法实现线性注意力
  - 避免了 MHSA 中 Q、K 矩阵乘法的二次复杂度[10]

- **加权连接**：
  - 通过 Softmax 和 Concat 操作聚合所有局部块的注意力特征
  - 生成包含全局和局部信息的注意力特征 LA[10]

- **卷积位置嵌入（CPE）**：
  - 类似于传统 MHSA，引入位置信息以保持空间关系[10]

#### **步骤三：多头机制与输出生成**

```
多头注意力特征：LA ∈ R^(H×W×C)
↓
特征整合：Conv1×1(LA)
↓
残差连接：X̄ = Conv1×1(LA) + X
↓
输出：X̄ ∈ R^(H×W×C)
```

- **多头设计**：FMA 采用 8 个注意力头，模仿 MHSA 的多头机制[12]
- **残差连接**：保持梯度流动和特征传递[9]

---

### 完整数学表达式：

**空间-频谱交互：**
\[
\bar{A} = \text{RealFFT}(\text{LN}(X)), \quad \mathbb{R}^{H \times W \times C} \rightarrow \mathbb{C}^{H \times \frac{W}{2} \times 2C}
\]
\[
\hat{A} = \text{Conv}_{1 \times 1}(\bar{A}), \quad \mathbb{R}^{H \times \frac{W}{2} \times 2C} \rightarrow \mathbb{R}^{H \times \frac{W}{2} \times 2C}
\]
\[
A = \text{IRealFFT}(\hat{A}), \quad \mathbb{R}^{H \times \frac{W}{2} \times 2C} \rightarrow \mathbb{R}^{H \times W \times C}
\]

**区域调制：**
\[
V = \text{Conv}_{1 \times 1}(\text{LN}(X))
\]
\[
LA = \text{Softmax}\left(\text{Concat}_{1 \leq n \leq N}(A_n \otimes V_n)\right) + \text{CPE}(X)
\]

**输出：**
\[
\bar{X} = \text{Conv}_{1 \times 1}(LA) + X
\]

[9][10]

---

## 3. 总结

### FMA 的核心优势：

#### **1. 计算效率显著提升**
- **线性复杂度**：相比 MHSA 的 O(N²) 复杂度，FMA 实现了 O(N) 的线性复杂度[3][9]
- **参数高效**：通过傅里叶变换和局部块注意力，在更少参数下实现更强的建模能力

**复杂度对比：**
| 机制 | 计算复杂度 | 全局建模 |
|------|-----------|---------|
| MHSA | O(N²) | ✓ |
| 大核卷积 | O(N·K²) | 部分 |
| **FMA** | **O(N)** | **✓** |

#### **2. 全局-局部平衡建模**
- **全局建模**：通过傅里叶域操作，即使在早期层也能捕捉全局感受野[9]
- **局部建模**：通过块分割和区域调制，保持对局部细节的敏感性[4][9]
- **长短期依赖**：同时实现长期（全局）和短期（局部）依赖关系的建模[4]

#### **3. 特征表达能力增强**
- **冗余抑制**：傅里叶变换能有效去除输入特征的冗余，激活更重要的特征值[24]
- **稀疏激活**：相比大核卷积激活所有值，FMA 产生稀疏的激活图，具有更强的判别能力[24]
- **细节保留**：输出特征包含更丰富的纹理线索，有利于准确的超分辨率重建[24]

---

### 实验验证：

#### **消融实验（表5）：**
| 模型 | 空间-频谱交互 | 区域调制 | 多头 | PSNR/SSIM |
|------|-------------|---------|------|-----------|
| A (基线) | ✗ | ✗ | ✗ | 32.10/0.8934 |
| B | ✓ | ✗ | ✗ | 32.12/0.8937 |
| C | ✓ | ✓ | ✗ | 32.15/0.8942 |
| **D (完整 FMA)** | **✓** | **✓** | **✓** | **32.17/0.8944** |

[24]

**关键发现：**
1. 空间-频谱交互带来 +0.02dB 提升，验证了全局建模的有效性
2. 区域调制进一步提升 +0.03dB，证明了局部-全局结合的重要性
3. 多头机制额外提升 +0.02dB，完整 FMA 达到最佳性能

#### **与大核卷积对比（表6）：**
| 方法 | FLOPs | PSNR/SSIM |
|------|-------|-----------|
| + 大核卷积 (11×11) | 21.6G | 32.14/0.8940 |
| **+ FMA (空间-频谱)** | **21.9G** | **32.17/0.8944** |

[24]

- FMA 在略微增加 FLOPs 的情况下，性能优于大核卷积
- 可视化显示 FMA 产生更稀疏、更有判别力的激活图

---

### 在 SRConvNet 中的作用：

FMA 作为 SRConvNet 的核心组件之一：
- **与 DML 协同**：FMA 负责全局依赖性建模，DML 负责局部多尺度特征学习[7][8]
- **变压器风格**：FMA 模仿 MHSA 的功能，但以更高效的方式实现[3][4]
- **轻量化设计**：在保持强大建模能力的同时，显著降低计算复杂度，适合移动设备部署[1][3]

通过 FMA 和 DML 的结合，SRConvNet 在轻量级图像超分辨率任务中实现了效率和准确性的最佳平衡，在参数量和 FLOPs 显著低于现有方法的情况下，达到了可比甚至更优的重建性能[3][14][19]。