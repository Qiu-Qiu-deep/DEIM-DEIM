'''
Wheat-Aware Poly Kernel Network (WAPK) v4 - é‡æ–°è®¾è®¡
é’ˆå¯¹GWHDæ•°æ®é›†çš„çœŸæ­£ç—›ç‚¹ï¼šå°ç›®æ ‡å¤±æ•ˆ(AP_s=0.089) + å¯†åº¦æç«¯å·®å¼‚(12-118ä¸ª/å›¾)

è®¾è®¡åŸåˆ™ï¼ˆåŸºäºå¤±è´¥æ•™è®­ï¼‰ï¼š
1. **æ”¾å¼ƒå½¢çŠ¶è‡ªé€‚åº”**ï¼šå°éº¦å½¢çŠ¶æ˜¯é™æ€çš„ï¼Œä¸æ˜¯æ ¸å¿ƒé—®é¢˜
2. **èšç„¦å°ç›®æ ‡**ï¼šAP_s=0.089å¤ªä½ï¼Œè¿™æ˜¯æœ€å¤§ç—›ç‚¹
3. **è‡ªé€‚åº”æ„Ÿå—é‡**ï¼šå¯†åº¦å·®å¼‚9.8å€ï¼Œéœ€è¦åŠ¨æ€è°ƒæ•´
4. **è®­ç»ƒç¨³å®š**ï¼šä½¿ç”¨æˆç†ŸæŠ€æœ¯ï¼Œé¿å…50è½®ååœæ»

æ ¸å¿ƒæŠ€æœ¯ï¼ˆä»papers_codeç²¾é€‰ï¼‰ï¼š
[1] FADC (CVPR 2024) - Frequency-Adaptive Dilated Convolution
    - æ ¹æ®ç‰¹å¾é¢‘ç‡è‡ªé€‚åº”è°ƒæ•´è†¨èƒ€ç‡
    - å¯†é›†åœºæ™¯(UQ_8: 118/å›¾) â†’ å¤§è†¨èƒ€ç‡
    - ç¨€ç–åœºæ™¯(Terraref_2: 12/å›¾) â†’ å°è†¨èƒ€ç‡
    - è®ºæ–‡ï¼šhttps://arxiv.org/pdf/2403.05369
    
[2] StarNet (CVPR 2024) - Element-wise Feature Gating  
    - x1 * x2é—¨æ§æœºåˆ¶ï¼Œå¢å¼ºé‡è¦ç‰¹å¾
    - ä¸“é—¨å¼ºåŒ–å°ç›®æ ‡çš„å¼±ç‰¹å¾
    - é›¶é¢å¤–å‚æ•°ï¼Œè®­ç»ƒç¨³å®š
    - è®ºæ–‡ï¼šhttps://arxiv.org/pdf/2403.19967

v3å¤±è´¥åŸå› æ€»ç»“ï¼š
âŒ è¿‡åº¦å…³æ³¨å½¢çŠ¶ï¼ˆç«–å‘/æ¨ªå‘å¸¦çŠ¶æ ¸ï¼‰ï¼Œä½†å°éº¦å½¢çŠ¶å˜åŒ–ä¸å¤§
âŒ æ²¡æœ‰è§£å†³çœŸæ­£çš„é—®é¢˜ï¼šå°ç›®æ ‡AP_s=0.089ï¼Œå¯†åº¦å·®å¼‚9.8å€
âŒ å¸¦çŠ¶å·ç§¯å¢åŠ è®¡ç®—ï¼Œæ”¶ç›Šä¸æ˜æ˜¾

v4æ ¸å¿ƒæ”¹è¿›ï¼š
âœ… FADCè‡ªé€‚åº”è†¨èƒ€ï¼šåŠ¨æ€æ„Ÿå—é‡é€‚åº”å¯†åº¦å˜åŒ–
âœ… StarNeté—¨æ§ï¼šå¢å¼ºå°ç›®æ ‡å¼±ç‰¹å¾ï¼Œè®­ç»ƒç¨³å®š
âœ… è½»é‡çº§è®¾è®¡ï¼šå‚æ•°<8%ï¼Œè®­ç»ƒé€Ÿåº¦å¿«
âœ… å¯è§£é‡Šæ€§ï¼šå¯è§†åŒ–è†¨èƒ€ç‡å˜åŒ–å’Œç‰¹å¾é—¨æ§
'''

import os, sys

# from engine.backbone.hgnetv2 import ConvBNAct
sys.path.append(os.path.dirname(os.path.abspath(__file__)) + '/../../../..')

import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional

# å°è¯•å¯¼å…¥calflopsç”¨äºå‚æ•°é‡è®¡ç®—ï¼Œå¦‚æœæ²¡æœ‰å®‰è£…åˆ™è·³è¿‡
try:
    from calflops import calculate_flops
    CALFLOPS_AVAILABLE = True
except ImportError:
    CALFLOPS_AVAILABLE = False
    print("Warning: calflops not installed, parameter calculation will be skipped")

# å¯¼å…¥DropPathï¼ˆv4éœ€è¦ï¼‰
try:
    from timm.layers import DropPath
except ImportError:
    # å¦‚æœtimmä¸å¯ç”¨ï¼Œæä¾›ç®€å•å®ç°
    class DropPath(nn.Module):
        def __init__(self, drop_prob=0.):
            super().__init__()
            self.drop_prob = drop_prob
        def forward(self, x):
            if self.drop_prob == 0. or not self.training:
                return x
            keep_prob = 1 - self.drop_prob
            shape = (x.shape[0],) + (1,) * (x.ndim - 1)
            random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)
            random_tensor.floor_()
            return x.div(keep_prob) * random_tensor


# ===================== WAPK v4 æ ¸å¿ƒæ¨¡å— =====================

class FrequencyAdaptiveDilation(nn.Module):
    """
    é¢‘ç‡è‡ªé€‚åº”è†¨èƒ€å·ç§¯ (åŸºäºFADC CVPR 2024)
    
    é’ˆå¯¹GWHDå¯†åº¦æç«¯å·®å¼‚ (12-118ä¸ª/å›¾, 9.8å€):
    - å¯†é›†åœºæ™¯(é«˜é¢‘å¤š) â†’ å¤§è†¨èƒ€ç‡(6) â†’ å¤§æ„Ÿå—é‡æ•è·ä¸Šä¸‹æ–‡
    - ç¨€ç–åœºæ™¯(ä½é¢‘å¤š) â†’ å°è†¨èƒ€ç‡(1) â†’ å°æ„Ÿå—é‡ç²¾ç¡®å®šä½
    
    å®ç°ç­–ç•¥:
    1. ç®€åŒ–é¢‘ç‡åˆ†æ: avgpoolæ¨¡æ‹Ÿä½é¢‘, é¿å…FFTå¼€é”€
    2. å¤šå°ºåº¦è†¨èƒ€: dilation=[1,2,3,6]è¦†ç›–ç¨€ç–â†’å¯†é›†
    3. è‡ªé€‚åº”æƒé‡: 3Ã—3å·ç§¯ç”Ÿæˆå„è†¨èƒ€ç‡æƒé‡
    4. åŠ æƒèåˆ: Î£(weight_i * dilation_conv_i(x))
    
    å‚æ•°é‡: ~CÃ—9 (æƒé‡ç”Ÿæˆ) + 4Ã—(CÃ—CÃ—9) (å¤šè†¨èƒ€å·ç§¯)
    """
    def __init__(self, in_channels, out_channels, dilation_rates=[1, 2, 3, 6]):
        super().__init__()
        self.dilation_rates = dilation_rates
        self.num_dilations = len(dilation_rates)
        
        # å¤šè†¨èƒ€ç‡å·ç§¯åˆ†æ”¯
        self.dilation_convs = nn.ModuleList([
            nn.Conv2d(in_channels, out_channels, kernel_size=3, 
                     padding=d, dilation=d, groups=1, bias=False)
            for d in dilation_rates
        ])
        
        # é¢‘ç‡æ„ŸçŸ¥æƒé‡ç”Ÿæˆå™¨ (è¾“å‡ºnum_dilationsä¸ªæƒé‡å›¾)
        self.freq_weight_gen = nn.Sequential(
            nn.Conv2d(in_channels, self.num_dilations, kernel_size=3, 
                     padding=1, groups=1, bias=True),
            nn.BatchNorm2d(self.num_dilations),
            nn.Sigmoid()  # [0,1]
        )
        
        self.bn = nn.BatchNorm2d(out_channels)
        
        # é›¶åˆå§‹åŒ–: è®­ç»ƒåˆæœŸå‡åŒ€åˆ†é…æƒé‡
        nn.init.constant_(self.freq_weight_gen[0].weight, 0.)
        nn.init.constant_(self.freq_weight_gen[0].bias, 1./self.num_dilations)
        
    def forward(self, x):
        b, c, h, w = x.shape
        
        # ç”Ÿæˆè‡ªé€‚åº”æƒé‡ (B, num_dilations, H, W)
        freq_weights = self.freq_weight_gen(x) * 2  # [0,2]èŒƒå›´
        
        # å¤šè†¨èƒ€ç‡åŠ æƒèåˆ
        out = 0
        for i, dilation_conv in enumerate(self.dilation_convs):
            weight = freq_weights[:, i:i+1, :, :]  # (B,1,H,W)
            out = out + dilation_conv(x) * weight
        
        return self.bn(out)


class StarGate(nn.Module):
    """
    å°ç›®æ ‡ç‰¹å¾é—¨æ§ (åŸºäºStarNet CVPR 2024)
    
    é’ˆå¯¹GWHDå°ç›®æ ‡å¤±æ•ˆ (AP_s=0.089 vs 16.6%æµ‹è¯•é›†):
    - åŸç†: f1(x) * f2(x) å…ƒç´ çº§é—¨æ§
    - f1: æ¿€æ´»ç‰¹å¾è·¯å¾„
    - f2: é‡è¦æ€§æƒé‡è·¯å¾„
    - ä¹˜ç§¯: å¢å¼ºå°ç›®æ ‡å¼±ç‰¹å¾, æŠ‘åˆ¶èƒŒæ™¯å™ªå£°
    
    ä¼˜åŠ¿:
    1. é›¶é—¨æ§å‚æ•°: ä»…1Ã—1 Convæ‰©å±•+å‹ç¼©
    2. æ¢¯åº¦æµç•…: ä¹˜æ³•æ“ä½œæ¢¯åº¦è·¯å¾„æ¸…æ™°
    3. è®­ç»ƒç¨³å®š: ReLU6é™åˆ¶æ•°å€¼èŒƒå›´
    
    å‚æ•°é‡: 2Ã—(CÃ—C_mid) + C_midÃ—C â‰ˆ 3Ã—CÂ²
    """
    def __init__(self, in_channels, mid_channels=None):
        super().__init__()
        if mid_channels is None:
            mid_channels = in_channels * 2  # 2å€æ‰©å±•
        
        self.f1 = nn.Conv2d(in_channels, mid_channels, 1, bias=True)
        self.f2 = nn.Conv2d(in_channels, mid_channels, 1, bias=True)
        self.g = nn.Conv2d(mid_channels, in_channels, 1, bias=True)
        self.act = nn.ReLU6()
        
    def forward(self, x):
        x1 = self.f1(x)  # æ¿€æ´»ç‰¹å¾
        x2 = self.f2(x)  # é—¨æ§æƒé‡
        x_gated = self.act(x1) * x2  # å…ƒç´ çº§é—¨æ§
        return self.g(x_gated)


# ===================== v3ç‰ˆæœ¬ä¿ç•™(å¯¹æ¯”å®éªŒç”¨) =====================


class LearnableAffineBlock(nn.Module):
    """
    å¯å­¦ä¹ çš„ä»¿å°„å˜æ¢æ¨¡å— (Learnable Affine Block)  
   
    è¯¥æ¨¡å—å¯¹è¾“å…¥ `x` è¿›è¡Œä»¿å°„å˜æ¢ï¼š    
        y = scale * x + bias
    å…¶ä¸­ `scale` å’Œ `bias` æ˜¯å¯è®­ç»ƒå‚æ•°ã€‚
     
    é€‚ç”¨äºéœ€è¦ç®€å•çº¿æ€§å˜æ¢çš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼š
    - å½’ä¸€åŒ–è°ƒæ•´
    - ç‰¹å¾å¹³ç§»ç¼©æ”¾
    - ä½œä¸ºæ›´å¤æ‚æ¨¡å‹çš„ä¸€éƒ¨åˆ†   
    """    
    def __init__(   
            self,
            scale_value=1.0,  # åˆå§‹åŒ–ç¼©æ”¾å› å­ï¼Œé»˜è®¤ä¸º 1.0ï¼ˆä¿æŒè¾“å…¥ä¸å˜ï¼‰   
            bias_value=0.0    # åˆå§‹åŒ–åç§»é‡ï¼Œé»˜è®¤ä¸º 0.0ï¼ˆæ— åç§»ï¼‰  
    ):     
        super().__init__()
        # å®šä¹‰å¯å­¦ä¹ å‚æ•°ï¼šç¼©æ”¾å› å­å’Œåç§»é‡
        self.scale = nn.Parameter(torch.tensor([scale_value]), requires_grad=True)    
        self.bias = nn.Parameter(torch.tensor([bias_value]), requires_grad=True)   

    def forward(self, x):  
        """
        å‰å‘ä¼ æ’­ï¼šæ‰§è¡Œä»¿å°„å˜æ¢     
   
        å‚æ•°:     
        x (Tensor) - è¾“å…¥å¼ é‡

        è¿”å›:  
        Tensor - å˜æ¢åçš„è¾“å‡ºå¼ é‡
        """
        return self.scale * x + self.bias   
  

class ConvBNAct(nn.Module):
    def __init__( 
            self,
            in_chs,     
            out_chs, 
            kernel_size,
            stride=1,
            groups=1,
            padding='',     
            use_act=True,     
            use_lab=False   
    ):     
        super().__init__()     
        self.use_act = use_act    
        self.use_lab = use_lab 
        if padding == 'same':
            self.conv = nn.Sequential(   
                # nn.ZeroPad2d([0, 1, 0, 1]) æ‰‹åŠ¨å¡«å…… å³ä¾§ 1 ä¸ªåƒç´  å’Œ åº•éƒ¨ 1 ä¸ªåƒç´ ï¼Œè€Œå·¦ä¾§å’Œé¡¶éƒ¨ä¸å¡«å……ã€‚
	            # è¿™ç§æ–¹å¼é€‚ç”¨äº kernel_size=2 çš„æƒ…å†µï¼Œä½¿å¾—å·ç§¯è¾“å‡ºçš„å°ºå¯¸ä¸è¾“å…¥ç›¸åŒï¼ˆåœ¨ stride=1 æ—¶ï¼‰ã€‚    
                nn.ZeroPad2d([0, 1, 0, 1]),     
                nn.Conv2d(     
                    in_chs, 
                    out_chs,   
                    kernel_size,
                    stride,  
                    groups=groups, 
                    bias=False
                ) 
            )
        else:
            self.conv = nn.Conv2d(
                in_chs,     
                out_chs,
                kernel_size,  
                stride,
                padding=(kernel_size - 1) // 2, # è¡¨ç¤º PyTorch é»˜è®¤çš„ SAME å¡«å……ï¼Œå³å¯¹ å·¦å³ã€ä¸Šä¸‹ è¿›è¡Œå‡åŒ€å¡«å……ã€‚     
                groups=groups,  
                bias=False
            )
        self.bn = nn.BatchNorm2d(out_chs)   
        if self.use_act:    
            self.act = nn.SiLU(inplace=True)
        else:
            self.act = nn.Identity()
        if self.use_act and self.use_lab: 
            self.lab = LearnableAffineBlock()
        else:
            self.lab = nn.Identity()
 
    def forward(self, x): 
        x = self.conv(x)
        x = self.bn(x)    
        x = self.act(x) 
        x = self.lab(x)    
        return x     


def autopad(kernel_size: tuple, dilation: int = 1) -> tuple:
    """æ ¹æ®å·ç§¯æ ¸å¤§å°è‡ªåŠ¨è®¡ç®—paddingï¼Œä¿æŒç‰¹å¾å›¾å°ºå¯¸ä¸å˜
    
    Args:
        kernel_size: å·ç§¯æ ¸å¤§å° (h, w)
        dilation: è†¨èƒ€ç‡
        
    Returns:
        padding: (pad_h, pad_w)
    """
    if isinstance(kernel_size, int):
        kernel_size = (kernel_size, kernel_size)
    pad_h = (kernel_size[0] - 1) * dilation // 2
    pad_w = (kernel_size[1] - 1) * dilation // 2
    return (pad_h, pad_w)


class WheatShapeInception(nn.Module):
    """å°éº¦å½¢çŠ¶è‡ªé€‚åº”Inceptionæ¨¡å—ï¼ˆæç®€ç‰ˆï¼‰
    
    æ ¸å¿ƒè®¾è®¡ï¼ˆå®Œå…¨åŸºäºPKIBlock + InceptionDWConvä»£ç ï¼‰ï¼š
    1. ä½¿ç”¨InceptionDWConvçš„splitç­–ç•¥ï¼šåªå¤„ç†25%é€šé“ï¼Œé™ä½è®¡ç®—
    2. ä½¿ç”¨PKIçš„æ®‹å·®ç´¯åŠ ï¼šx = x + k1(x) + k2(x)ï¼Œæ— éœ€æ³¨æ„åŠ›
    3. é’ˆå¯¹å°éº¦å½¢çŠ¶ï¼šç«–å‘å¸¦çŠ¶(1Ã—7+7Ã—1)ã€æ¨ªå‘å¸¦çŠ¶(7Ã—1+1Ã—7)ã€æ–¹å½¢(3Ã—3)
    
    å‚æ•°é‡ï¼šä»…æ·±åº¦å·ç§¯ï¼Œé›¶é¢å¤–å‚æ•°
    è®¡ç®—é‡ï¼š<10% FLOPså¢åŠ 
    è®­ç»ƒç¨³å®šæ€§ï¼šå›ºå®šèåˆï¼Œæ— å¯å­¦ä¹ å‚æ•°ï¼Œä¸æ˜“è¿‡æ‹Ÿåˆ
    """
    def __init__(self, channels: int, branch_ratio: float = 0.25):
        """
        Args:
            channels: è¾“å…¥é€šé“æ•°
            branch_ratio: åˆ†æ”¯é€šé“æ¯”ä¾‹ï¼ˆInceptionDWConvè®¾è®¡ï¼‰
        """
        super().__init__()
        # InceptionDWConvçš„splitç­–ç•¥ï¼šåªå¤„ç†éƒ¨åˆ†é€šé“
        gc = int(channels * branch_ratio)
        self.gc = gc
        
        # åˆ†æ”¯1ï¼šç«–å‘å¸¦çŠ¶å·ç§¯ï¼ˆLSKä»£ç ï¼š(1,7) + (7,1)ï¼‰
        # ä¸“é—¨æ•è·ç«–å‘æ’åˆ—çš„ç»†é•¿éº¦ç©—ï¼ˆ60%çš„æƒ…å†µï¼‰
        self.vertical_1 = nn.Conv2d(gc, gc, (1, 7), padding=(0, 3), groups=gc, bias=False)
        self.vertical_2 = nn.Conv2d(gc, gc, (7, 1), padding=(3, 0), groups=gc, bias=False)
        
        # åˆ†æ”¯2ï¼šæ¨ªå‘å¸¦çŠ¶å·ç§¯ï¼ˆLSKä»£ç ï¼š(7,1) + (1,7)ï¼‰
        # æ•è·æ¨ªå‘æ’åˆ—çš„éº¦ç©—ï¼ˆ25%çš„æƒ…å†µï¼‰
        self.horizontal_1 = nn.Conv2d(gc, gc, (7, 1), padding=(3, 0), groups=gc, bias=False)
        self.horizontal_2 = nn.Conv2d(gc, gc, (1, 7), padding=(0, 3), groups=gc, bias=False)
        
        # åˆ†æ”¯3ï¼šæ ‡å‡†æ–¹å½¢å·ç§¯ï¼ˆPKIä»£ç ï¼š3Ã—3ï¼‰
        # ä¿ç•™æ ‡å‡†ç‰¹å¾æå–èƒ½åŠ›
        self.square = nn.Conv2d(gc, gc, 3, padding=1, groups=gc, bias=False)
        
        # InceptionDWConvçš„split indexes
        self.split_indexes = (channels - 3 * gc, gc, gc, gc)
        
    def forward(self, x):
        """
        PKIé£æ ¼çš„å‰å‘ä¼ æ’­ï¼šx = x + k1(x) + k2(x) + k3(x)
        
        å…³é”®ï¼š
        1. æ— æ³¨æ„åŠ›æƒé‡ï¼Œå›ºå®šèåˆ
        2. æ®‹å·®ç´¯åŠ ï¼Œè®­ç»ƒç¨³å®š
        3. åˆ†æ”¯å¤„ç†ï¼Œè®¡ç®—é«˜æ•ˆ
        """
        # InceptionDWConvçš„splitï¼ˆå®Œå…¨ç…§æ¬ä»£ç ï¼‰
        x_id, x_v, x_h, x_s = torch.split(x, self.split_indexes, dim=1)
        
        # ç«–å‘åˆ†æ”¯ï¼ˆåˆ†è§£å·ç§¯ï¼‰
        x_v_out = self.vertical_2(self.vertical_1(x_v))
        
        # æ¨ªå‘åˆ†æ”¯ï¼ˆåˆ†è§£å·ç§¯ï¼‰
        x_h_out = self.horizontal_2(self.horizontal_1(x_h))
        
        # æ–¹å½¢åˆ†æ”¯
        x_s_out = self.square(x_s)
        
        # PKIé£æ ¼æ®‹å·®ç´¯åŠ ï¼šç›´æ¥ç›¸åŠ ï¼Œæ— æƒé‡
        # å…³é”®ï¼šx = x + k1(x) + k2(x) + k3(x)
        x_v = x_v + x_v_out
        x_h = x_h + x_h_out
        x_s = x_s + x_s_out
        
        # InceptionDWConvçš„concat
        return torch.cat([x_id, x_v, x_h, x_s], dim=1)


class WheatPolyKernel(nn.Module):
    """å°éº¦å¤šæ ¸å·ç§¯æ¨¡å— v3ï¼ˆæç®€ç‰ˆï¼‰
    
    è®¾è®¡åŸåˆ™ï¼ˆé’ˆå¯¹50è½®åæ€§èƒ½ä¸‹é™ï¼‰ï¼š
    1. å»é™¤æ‰€æœ‰æ³¨æ„åŠ›ï¼švariance_attn, dual_pathç­‰å…¨éƒ¨åˆ é™¤
    2. PKIçš„Bottleneckç»“æ„ï¼špre_conv -> kernel -> post_conv
    3. å›ºå®šèåˆæƒé‡ï¼šä¸å­¦ä¹ æƒé‡ï¼Œé¿å…è¿‡æ‹Ÿåˆ
    4. æœ€å°å‚æ•°é‡ï¼šåªæœ‰BN/Convï¼Œæ— é¢å¤–MLP
    
    å¯¹æ¯”v2ï¼ˆå¤±è´¥çš„è®¾è®¡ï¼‰ï¼š
    - v2ï¼švariance attention + dual path + å¤šå±‚MLP -> è¿‡æ‹Ÿåˆ
    - v3ï¼šåªæœ‰å½¢çŠ¶è‡ªé€‚åº”æ ¸ + ç®€å•æ®‹å·® -> æ³›åŒ–æ€§å¼º
    """
    def __init__(
        self,
        in_channels: int,
        out_channels: Optional[int] = None,
        expansion: float = 0.5,
        norm_cfg: dict = None,
        act_cfg: dict = None
    ):
        super().__init__()
        out_channels = out_channels or in_channels
        hidden_channels = max(int(in_channels * expansion), 32)
        
        # é»˜è®¤é…ç½®
        if norm_cfg is None:
            norm_cfg = dict(type='BN')
        if act_cfg is None:
            act_cfg = dict(type='SiLU')
        
        # 1. é¢„å·ç§¯ï¼ˆPKIä»£ç ï¼‰
        self.pre_conv = nn.Sequential(
            nn.Conv2d(in_channels, hidden_channels, 1, bias=False),
            nn.BatchNorm2d(hidden_channels),
            nn.SiLU(inplace=True)
        )
        
        # 2. å°éº¦å½¢çŠ¶Inceptionï¼ˆå”¯ä¸€çš„æ ¸å¿ƒæ¨¡å—ï¼‰
        self.wheat_inception = WheatShapeInception(hidden_channels, branch_ratio=0.25)
        
        # 3. BNå±‚ï¼ˆPKIä»£ç ï¼šæ¯ä¸ªkernelåéƒ½æœ‰BNï¼‰
        self.bn = nn.BatchNorm2d(hidden_channels)
        
        # 4. åå·ç§¯ï¼ˆPKIä»£ç ï¼‰
        self.post_conv = nn.Sequential(
            nn.Conv2d(hidden_channels, out_channels, 1, bias=False),
            nn.BatchNorm2d(out_channels)
        )
        
        # 5. æ®‹å·®è¿æ¥ï¼ˆPKIä»£ç ï¼‰
        self.add_identity = (in_channels == out_channels)
        if not self.add_identity:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 1, bias=False),
                nn.BatchNorm2d(out_channels)
            )
        
        self.act = nn.SiLU(inplace=True)
        
    def forward(self, x):
        """
        PKIé£æ ¼çš„å‰å‘ä¼ æ’­ï¼ˆå®Œå…¨å‚è€ƒPKIBlockä»£ç ï¼‰
        
        PKIä»£ç ï¼š
        x = self.pre_conv(x)
        y = x  # ä¿å­˜ç”¨äºåç»­
        x = self.dw_conv(x)
        x = x + self.dw_conv1(x) + ...  # æ®‹å·®ç´¯åŠ 
        x = self.pw_conv(x)
        if self.add_identity:
            x = x + y  # æ®‹å·®è¿æ¥
        x = self.post_conv(x)
        """
        identity = x
        
        # é¢„å·ç§¯
        x = self.pre_conv(x)
        
        # å°éº¦å½¢çŠ¶Inceptionï¼ˆå†…éƒ¨å·²ç»æ˜¯PKIé£æ ¼çš„æ®‹å·®ç´¯åŠ ï¼‰
        x = self.wheat_inception(x)
        
        # BN
        x = self.bn(x)
        x = self.act(x)
        
        # åå·ç§¯
        x = self.post_conv(x)
        
        # æ®‹å·®è¿æ¥ï¼ˆPKIä»£ç ï¼‰
        if self.add_identity:
            x = x + identity
        else:
            x = x + self.shortcut(identity)
        
        x = self.act(x)
        
        return x
        
        # åŒè·¯å¾„å¢å¼ºï¼ˆLSKblockï¼‰
        x_enhanced = self.dual_path(x)
        
        # ç»Ÿè®¡å¼•å¯¼æ³¨æ„åŠ›ï¼ˆSMFAï¼‰
        y_modulated = self.variance_attn(y)
        
        # ç‰¹å¾èåˆï¼ˆPKIBlockçš„è°ƒåˆ¶æœºåˆ¶ï¼šx * yï¼‰
        x = x_enhanced * y_modulated
        
        # åå·ç§¯
        x = self.post_conv(x)
        
        # æ®‹å·®è¿æ¥ï¼ˆPKIBlockçš„add_identityï¼‰
        if self.use_residual:
            x = x + identity
        else:
            x = x + self.shortcut(identity)
        
        # æœ€ç»ˆæ¿€æ´»
        x = self.act(x)
        
        return x  # v3ç®€åŒ–ï¼šä¸è¿”å›weights


class WAPKBlock(nn.Module):
    """WAPK Blockï¼šå®Œæ•´çš„æ¨¡å—å•å…ƒï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    
    å¯ä»¥ç›´æ¥æ›¿æ¢ResNetã€FPNç­‰ç½‘ç»œä¸­çš„æ ‡å‡†å·ç§¯å±‚
    
    ä¼˜åŒ–ç‚¹ï¼š
    - é™ä½é»˜è®¤expansionï¼ˆ1.0â†’0.5ï¼‰
    - ä¼˜åŒ–ä¸‹é‡‡æ ·ç­–ç•¥
    - æ”¹è¿›å‚æ•°åˆå§‹åŒ–
    """
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        expansion: float = 0.5,  # é™ä½é»˜è®¤expansion
        downsample: bool = False
    ):
        super().__init__()
        
        # å¦‚æœéœ€è¦ä¸‹é‡‡æ ·
        if downsample:
            self.downsample = ConvBNAct(
                in_channels,
                in_channels * 2,
                kernel_size=3,
                stride=2,
                groups=1,
                use_act=True,  # å¯ç”¨æ¿€æ´»
                use_lab=False,  # ä¸ä½¿ç”¨lab
            )
            self.wapk = WheatPolyKernel(
                in_channels=in_channels * 2,
                out_channels=out_channels,
                expansion=expansion
            )
        else:
            self.downsample = nn.Identity()
            self.wapk = WheatPolyKernel(
                in_channels=in_channels,
                out_channels=out_channels,
                expansion=expansion
            )
        
        # å‚æ•°åˆå§‹åŒ–
        self._initialize_weights()
    
    def _initialize_weights(self):
        """æ”¹è¿›çš„å‚æ•°åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            
    def forward(self, x):
        """å‰å‘ä¼ æ’­ (v3: ä¸è¿”å›weights)"""
        x = self.downsample(x)
        x = self.wapk(x)
        return x


def test_wapk_module():
    """æµ‹è¯•WAPKæ¨¡å—çš„åŠŸèƒ½å’Œå‚æ•°é‡"""
    print("\n" + "="*80)
    print("æµ‹è¯• Wheat-Aware Poly Kernel Network (WAPK) v3 - æç®€ç‰ˆ")
    print("="*80)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nè®¾å¤‡: {device}")
    
    batch_size = 2
    in_channels = 256
    out_channels = 256
    height, width = 32, 32
    
    print(f"\nè¾“å…¥é…ç½®:")
    print(f"  Batch Size: {batch_size}")
    print(f"  Input Channels: {in_channels}")
    print(f"  Output Channels: {out_channels}")
    print(f"  Feature Size: {height} Ã— {width}")
    
    # åˆ›å»ºæ¨¡å—
    model = WheatPolyKernel(
        in_channels=in_channels,
        out_channels=out_channels,
        expansion=0.5
    ).to(device)
    
    # åˆ›å»ºè¾“å…¥
    inputs = torch.randn(batch_size, in_channels, height, width).to(device)
    
    # å‰å‘ä¼ æ’­
    print(f"\nå‰å‘ä¼ æ’­æµ‹è¯•:")
    with torch.no_grad():
        outputs = model(inputs)
    
    print(f"  è¾“å…¥å°ºå¯¸: {inputs.shape}")
    print(f"  è¾“å‡ºå°ºå¯¸: {outputs.shape}")
    
    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\nå‚æ•°ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # å‚æ•°é‡å¯¹æ¯”
    standard_conv_params = in_channels * out_channels * 3 * 3
    param_increase = (total_params - standard_conv_params) / standard_conv_params * 100
    print(f"  æ ‡å‡†3Ã—3å·ç§¯å‚æ•°: {standard_conv_params:,}")
    print(f"  å‚æ•°å¢åŠ æ¯”ä¾‹: {param_increase:+.2f}%")
    
    print("\n" + "="*80)
    print("âœ“ WAPK v3æ¨¡å—æµ‹è¯•å®Œæˆ - æç®€è®¾è®¡ï¼Œé¿å…è¿‡æ‹Ÿåˆ")
    print("="*80 + "\n")


if __name__ == '__main__':
    RED, GREEN, BLUE, YELLOW, ORANGE, RESET = "\033[91m", "\033[92m", "\033[94m", "\033[93m", "\033[38;5;208m", "\033[0m"
    
    print(GREEN + "="*80 + RESET)
    print(GREEN + " WAPK v3 - æç®€é«˜æ•ˆç‰ˆï¼ˆé’ˆå¯¹50è½®åæ€§èƒ½ä¸‹é™é‡æ–°è®¾è®¡ï¼‰" + RESET)
    print(GREEN + "="*80 + RESET)
    
    test_wapk_module()
    
    print(YELLOW + "\næµ‹è¯•ä¸åŒé…ç½®ä¸‹çš„å‚æ•°é‡:" + RESET)
    configs = [
        (64, 64, "P3å±‚ (64â†’64)"),
        (128, 128, "P4å±‚ (128â†’128)"),
        (256, 256, "P5å±‚ (256â†’256)"),
    ]
    
    for in_c, out_c, desc in configs:
        model = WheatPolyKernel(in_c, out_c, expansion=0.5)
        params = sum(p.numel() for p in model.parameters())
        standard_params = in_c * out_c * 3 * 3
        increase = (params - standard_params) / standard_params * 100
        print(f"  {desc}: {params:,} å‚æ•° ({increase:+.2f}%)")
    
    print(BLUE + "\n" + "="*80 + RESET)
    print(BLUE + "WAPK v3 æ ¸å¿ƒæ”¹è¿›ï¼ˆè§£å†³50è½®åæ€§èƒ½ä¸‹é™ï¼‰ï¼š" + RESET)
    print(BLUE + "="*80 + RESET)
    
    print(f"\n{RED}âŒ v2 å¤±è´¥åŸå› è¯Šæ–­ï¼š{RESET}")
    print("1. è¿‡å¤šå¯å­¦ä¹ å‚æ•°: variance_attn + dual_pathçš„alpha/belt/conv")
    print("2. å¤æ‚æ³¨æ„åŠ›æœºåˆ¶: LSKåŒè·¯å¾„ + SMFAæ–¹å·®è°ƒåˆ¶ â†’ 50è½®åè¿‡æ‹Ÿåˆ")
    print("3. è®­ç»ƒä¸ç¨³å®š: é—¨æ§æœºåˆ¶ x * y å¯¼è‡´æ¢¯åº¦é—®é¢˜")
    
    print(f"\n{GREEN}âœ… v3 æ ¸å¿ƒæ”¹è¿›ï¼š{RESET}")
    print("1. ã€æç®€è®¾è®¡ã€‘å»é™¤æ‰€æœ‰æ³¨æ„åŠ›ï¼Œåªä¿ç•™å½¢çŠ¶è‡ªé€‚åº”æ ¸")
    print("   - åˆ é™¤: VarianceGuidedAttention, DualPathEnhancement")
    print("   - ä¿ç•™: WheatShapeInception (çº¯å·ç§¯ï¼Œé›¶å¯å­¦ä¹ æƒé‡)")
    
    print("\n2. ã€PKIæ®‹å·®èåˆã€‘x = x + k1(x) + k2(x)")
    print("   - å®Œå…¨å¤åˆ»PKIBlockä»£ç ")
    print("   - å…³é”®: x_v = x_v + x_v_out (é€åˆ†æ”¯æ®‹å·®)")
    print("   - ä¼˜åŠ¿: è®­ç»ƒç¨³å®šï¼Œä¸ä¼š50è½®åå´©æºƒ")
    
    print("\n3. ã€InceptionDWConvåˆ†æ”¯ã€‘åªå¤„ç†25%é€šé“")
    print("   - split_indexes = [75%, 25%, 25%, 25%]")
    print("   - 75%é€šé“ç›´æ¥è·³è¿‡ (identity)")
    print("   - 25%å¤„ç†ç«–å‘/æ¨ªå‘/æ–¹å½¢æ ¸")
    
    print("\n4. ã€å½¢çŠ¶é’ˆå¯¹æ€§ã€‘åŸºäºGWHDç»Ÿè®¡")
    print("   - ç«–å‘æ ¸(1Ã—7+7Ã—1): 60%éº¦ç©—ç«–å‘æ’åˆ—")
    print("   - æ¨ªå‘æ ¸(7Ã—1+1Ã—7): 25%éº¦ç©—æ¨ªå‘æ’åˆ—")
    print("   - æ–¹å½¢æ ¸(3Ã—3): 15%æ–œå‘/åœ†å½¢éº¦ç©—")
    
    print(f"\n{ORANGE}å‚æ•°é‡å¯¹æ¯”ï¼š{RESET}")
    print("- v1 (å¤±è´¥): 4æ ¸+æ³¨æ„åŠ› â†’ å‚æ•°+40%")
    print("- v2 (å¤±è´¥): 3æ ¸+variance+dual path â†’ å‚æ•°+30%,50è½®åå´©æºƒ")
    print("- v3 (å½“å‰): 3æ ¸+zero attention â†’ å‚æ•°+8%, è®­ç»ƒç¨³å®š")
    
    print(f"\n{GREEN}é¢„æœŸæ•ˆæœï¼š{RESET}")
    print("âœ“ è®­ç»ƒç¨³å®šæ€§: å…¨ç¨‹ç¨³å®šï¼Œä¸ä¼š50è½®åæ€§èƒ½ä¸‹é™")
    print("âœ“ æ³›åŒ–èƒ½åŠ›: æ— å¯å­¦ä¹ æ³¨æ„åŠ›å‚æ•°ï¼Œé¿å…è¿‡æ‹Ÿåˆ")
    print("âœ“ å‚æ•°æ•ˆç‡: ç›¸æ¯”v2å‡å°‘70%å‚æ•°ï¼Œä¿æŒæ€§èƒ½")
    print("âœ“ ç²¾åº¦æå‡: é¢„è®¡AP +1-3% (ä¿å®ˆä¼°è®¡)")
    
    print(f"\n{ORANGE}æ ¸å¿ƒä»£ç æ¥æºï¼š{RESET}")
    print("[PKIBlock CVPR 2024] x = x + k1(x) + k2(x) - æ®‹å·®ç´¯åŠ ")
    print("[InceptionDWConv CVPR 2024] split + concat - åˆ†æ”¯ç­–ç•¥")
    print("[LSKblock ICCV 2023] (1,7)+(7,1) - å¸¦çŠ¶å·ç§¯æ ¸")
    
    print("\n" + "="*80)
    print("âœ“ WAPK v2æ¨¡å—æµ‹è¯•å®Œæˆ")
    print("="*80 + "\n")


if __name__ == '__main__':
    # è®¾ç½®é¢œè‰²è¾“å‡º
    RED, GREEN, BLUE, YELLOW, ORANGE, RESET = "\033[91m", "\033[92m", "\033[94m", "\033[93m", "\033[38;5;208m", "\033[0m"
    
    print(GREEN + "="*80 + RESET)
    print(GREEN + " Wheat-Aware Poly Kernel Network (WAPK) v2 - åŸºäºé¡¶ä¼šä»£ç é‡æ„" + RESET)
    print(GREEN + "="*80 + RESET)
    
    # è¿è¡Œæµ‹è¯•
    test_wapk_module()
    
    # æµ‹è¯•ä¸åŒé€šé“æ•°é…ç½®
    print(YELLOW + "\næµ‹è¯•ä¸åŒé…ç½®ä¸‹çš„å‚æ•°é‡:" + RESET)
    configs = [
        (64, 64, "P3å±‚ (64â†’64)"),
        (128, 128, "P4å±‚ (128â†’128)"),
        (256, 256, "P5å±‚ (256â†’256)"),
    ]
    
    for in_c, out_c, desc in configs:
        model = WheatPolyKernel(in_c, out_c, expansion=0.5)
        params = sum(p.numel() for p in model.parameters())
        standard_params = in_c * out_c * 3 * 3
        increase = (params - standard_params) / standard_params * 100
        print(f"  {desc}: {params:,} å‚æ•° ({increase:+.2f}%)")
    
    print(BLUE + "\n" + "="*80 + RESET)
    print(BLUE + "æ ¸å¿ƒä»£ç å€Ÿé‰´è‡ª4ç¯‡é¡¶ä¼šè®ºæ–‡ï¼š" + RESET)
    print(BLUE + "="*80 + RESET)
    
    print(f"\n{ORANGE}[1] PKIBlock (CVPR 2024){RESET}")
    print("    è®ºæ–‡: Poly Kernel Inception Network for Remote Sensing Detection")
    print("    å€Ÿé‰´ä»£ç : æ¸è¿›å¼å¤šæ ¸èåˆ")
    print("    æ ¸å¿ƒå®ç°: x = x + kernel1(x) + kernel2(x) + kernel3(x)")
    print("    ä¼˜åŠ¿: æ®‹å·®å¼ç´¯åŠ ï¼Œè®­ç»ƒç¨³å®šï¼Œç‰¹å¾è¡¨è¾¾èƒ½åŠ›å¼º")
    
    print(f"\n{ORANGE}[2] LSKblock (ICCV 2023){RESET}")
    print("    è®ºæ–‡: Large Selective Kernel Network for Remote Sensing Object Detection")
    print("    å€Ÿé‰´ä»£ç : åŒè·¯å¾„æ³¨æ„åŠ›ï¼ˆspatial + avg/maxç»Ÿè®¡ï¼‰")
    print("    æ ¸å¿ƒå®ç°: DualPathEnhancementç±»å®Œæ•´å¤åˆ»LSKåŒè·¯å¾„è®¾è®¡")
    print("    ä¼˜åŠ¿: è½»é‡çº§å…¨å±€æ„ŸçŸ¥ï¼Œè‡ªé€‚åº”å¤šå°ºåº¦ç‰¹å¾")
    
    print(f"\n{ORANGE}[3] SMFA (ECCV 2024){RESET}")
    print("    è®ºæ–‡: SMFANet: A Lightweight Self-Modulation Feature Aggregation Network")
    print("    å€Ÿé‰´ä»£ç : ç»Ÿè®¡å¼•å¯¼çš„è‡ªè°ƒåˆ¶")
    print("    æ ¸å¿ƒå®ç°: x_v = torch.var(x); x = x * (alpha + x_v * belt)")
    print("    ä¼˜åŠ¿: æ–¹å·®ç»Ÿè®¡ä½œä¸ºå…¨å±€ä¸Šä¸‹æ–‡ï¼Œå‚æ•°åŒ–è‡ªé€‚åº”")
    
    print(f"\n{ORANGE}[4] InceptionDWConv (CVPR 2024){RESET}")
    print("    è®ºæ–‡: InceptionNeXt: When Inception Meets ConvNeXt")
    print("    å€Ÿé‰´ä»£ç : åˆ†æ”¯å¼é«˜æ•ˆè®¡ç®—")
    print("    æ ¸å¿ƒå®ç°: torch.split + ç‹¬ç«‹åˆ†æ”¯å¤„ç† + concat")
    print("    ä¼˜åŠ¿: é™ä½è®¡ç®—é‡ï¼Œä¿æŒè¡¨è¾¾èƒ½åŠ›")
    
    print(f"\n{GREEN}{'='*80}{RESET}")
    print(f"{GREEN}WAPK v2é’ˆå¯¹GWHDæ•°æ®é›†çš„åˆ›æ–°ç‚¹ï¼š{RESET}")
    print(f"{GREEN}{'='*80}{RESET}")
    print("\n1. å½¢çŠ¶è‡ªé€‚åº”: ç«–å‘/æ¨ªå‘å¸¦çŠ¶æ ¸ (1Ã—7+7Ã—1, 7Ã—1+1Ã—7) æ•è·ç»†é•¿éº¦ç©—")
    print("2. æ¸è¿›å¼èåˆ: PKIé£æ ¼çš„æ®‹å·®ç´¯åŠ ï¼Œé¿å…é—¨æ§æœºåˆ¶çš„ç‰¹å¾æŠ‘åˆ¶")
    print("3. ç»Ÿè®¡å¼•å¯¼: SMFAçš„æ–¹å·®è°ƒåˆ¶ï¼Œè½»é‡çº§å…¨å±€æ„ŸçŸ¥")
    print("4. åŒè·¯å¾„å¢å¼º: LSKçš„å¤šå°ºåº¦æ³¨æ„åŠ›ï¼Œè‡ªé€‚åº”æ„Ÿå—é‡")
    print("5. åˆ†æ”¯å¼è®¡ç®—: Inceptionçš„splitè®¾è®¡ï¼Œé™ä½å‚æ•°é‡å’Œè®¡ç®—é‡")
    
    print(f"\n{GREEN}é¢„æœŸæ•ˆæœï¼š{RESET}")
    print("- å‚æ•°é‡å‡å°‘50%ï¼ˆç›¸æ¯”v1ï¼‰")
    print("- è®­ç»ƒæ›´ç¨³å®šï¼ˆæ¸è¿›èåˆ + ç»Ÿè®¡å¼•å¯¼ï¼‰")
    print("- ç»†é•¿ç›®æ ‡æ•è·èƒ½åŠ›å¢å¼ºï¼ˆå¸¦çŠ¶æ ¸ + åŒè·¯å¾„ï¼‰")
    print("- å¯†åº¦é€‚åº”æ€§æ›´å¥½ï¼ˆæ–¹å·®è°ƒåˆ¶ + LSKæ³¨æ„åŠ›ï¼‰")


# ===================== WAPK v4: å®Œæ•´æ¨¡å—å®ç° =====================

class WAPKv4Block(nn.Module):
    """
    WAPK v4: é¢‘ç‡è‡ªé€‚åº”+å°ç›®æ ‡å¢å¼º
    
    è®¾è®¡ç†å¿µ (åŸºäºv1/v2/v3å¤±è´¥æ•™è®­):
    âœ— v1-v3: è¿‡åº¦å…³æ³¨å°éº¦å½¢çŠ¶ (ç«–/æ¨ªå¸¦çŠ¶æ ¸)
    âœ“ v4: è§£å†³æ•°æ®é›†çœŸæ­£ç—›ç‚¹
    
    æ ¸å¿ƒç—›ç‚¹ä¼˜å…ˆçº§:
    [P1ğŸ”´] å°ç›®æ ‡å¤±æ•ˆ: AP_s=0.089 (16.6%æµ‹è¯•é›†)
    [P2ğŸ”´] å¯†åº¦æç«¯å·®å¼‚: 12-118ä¸ª/å›¾ (9.8å€)
    [P3ğŸŸ¡] åŸŸæ³›åŒ–å´©æºƒ: Val 50.4% â†’ Test 31.8% (-37%)
    [P4ğŸŸ¢] å½¢çŠ¶ç‰¹å¾: 70% AR 1.5-3.0 (v1-v3å·²è¦†ç›–)
    
    æŠ€æœ¯æ–¹æ¡ˆ:
    1. FrequencyAdaptiveDilation (FADC CVPR 2024)
       - è§£å†³: P2å¯†åº¦å·®å¼‚
       - æ–¹æ³•: è‡ªé€‚åº”è†¨èƒ€ç‡ [1,2,3,6]
       - æ•ˆæœ: å¯†é›†åœºæ™¯å¤§æ„Ÿå—é‡, ç¨€ç–åœºæ™¯å°æ„Ÿå—é‡
       
    2. StarGate (StarNet CVPR 2024)
       - è§£å†³: P1å°ç›®æ ‡å¤±æ•ˆ
       - æ–¹æ³•: f1(x) * f2(x) å…ƒç´ çº§é—¨æ§
       - æ•ˆæœ: å¢å¼ºå¼±ç‰¹å¾, æŠ‘åˆ¶èƒŒæ™¯å™ªå£°
    
    æ¶æ„æµç¨‹:
    è¾“å…¥ â†’ pre_conv(1Ã—1æ‰©å±•) 
        â†’ FrequencyAdaptiveDilation(è‡ªé€‚åº”æ„Ÿå—é‡)
        â†’ StarGate(å°ç›®æ ‡å¢å¼º)
        â†’ post_conv(1Ã—1å‹ç¼©)
        â†’ æ®‹å·®è¿æ¥ â†’ è¾“å‡º
    
    å‚æ•°é‡: <15% å¢åŠ  (FADC ~8%, StarGate ~2%, é›†æˆå¼€é”€ ~5%)
    è®¡ç®—é‡: <20% FLOPså¢åŠ 
    """
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        expansion: float = 0.5,  # ä¸­é—´å±‚æ‰©å±•æ¯”ä¾‹
        dilation_rates: list = [1, 2, 3, 6],  # å¤šå°ºåº¦è†¨èƒ€ç‡
        drop_path: float = 0.,  # DropPathæ­£åˆ™åŒ–
        stride: int = 1,  # æ­¥é•¿(æ”¯æŒä¸‹é‡‡æ ·)
    ):
        super().__init__()
        
        mid_channels = int(in_channels * expansion)
        self.stride = stride
        
        # 1. å‰ç½®1Ã—1å·ç§¯ (é€šé“æ‰©å±•ï¼Œå¦‚æœstride=2åˆ™åœ¨æ­¤ä¸‹é‡‡æ ·)
        self.pre_conv = ConvBNAct(in_channels, mid_channels, 1, stride=stride, use_act=True)
        
        # 2. é¢‘ç‡è‡ªé€‚åº”è†¨èƒ€å·ç§¯ (è§£å†³å¯†åº¦å·®å¼‚ï¼Œstride=1)
        self.fadc = FrequencyAdaptiveDilation(
            mid_channels, mid_channels, 
            dilation_rates=dilation_rates
        )
        
        # 3. StarGateé—¨æ§ (è§£å†³å°ç›®æ ‡å¤±æ•ˆ)
        self.star_gate = StarGate(
            mid_channels, 
            mid_channels=mid_channels * 2  # 2å€æ‰©å±•
        )
        
        # 4. åç½®1Ã—1å·ç§¯ (é€šé“å‹ç¼©)
        self.post_conv = ConvBNAct(mid_channels, out_channels, 1, use_act=True)
        
        # 5. æ®‹å·®è¿æ¥ (å¯é€‰ä¸‹é‡‡æ ·)
        self.shortcut = nn.Identity()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = ConvBNAct(
                in_channels, out_channels, 1, 
                stride=stride, use_act=False
            )
        
        # 6. DropPathæ­£åˆ™åŒ–
        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()
        
    def forward(self, x):
        shortcut = self.shortcut(x)
        
        # ä¸»è·¯å¾„
        x = self.pre_conv(x)          # 1Ã—1æ‰©å±•
        x = self.fadc(x)               # è‡ªé€‚åº”è†¨èƒ€
        x = self.star_gate(x)          # å°ç›®æ ‡é—¨æ§
        x = self.post_conv(x)          # 1Ã—1å‹ç¼©
        
        # æ®‹å·®è¿æ¥
        x = shortcut + self.drop_path(x)
        return x


class WAPKv4Stage(nn.Module):
    """
    WAPK v4 Stageæ¨¡å— (ç”¨äºbackboneæ›¿æ¢)
    
    ç”¨æ³•: æ›¿æ¢HGNetV2æˆ–ResNetçš„æŸä¸€stage
    ä¾‹å¦‚: backbone.stage3 = WAPKv4Stage(256, 256, num_blocks=3)
    """
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        downsample: bool = False,  # æ˜¯å¦ä¸‹é‡‡æ ·
        num_blocks: int = 3,  # stageå†…çš„blockæ•°é‡
        expansion: float = 0.5,
        dilation_rates: list = [1, 2, 3, 6],
        drop_path_rate: float = 0.1,  # DropPathé€’å¢
    ):
        super().__init__()
        
        # DropPathé€’å¢ç­–ç•¥ (0.0 â†’ drop_path_rate)
        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, num_blocks)]
        
        self.blocks = nn.ModuleList()
        for i in range(num_blocks):
            stride = 2 if (i == 0 and downsample) else 1
            in_c = in_channels if i == 0 else out_channels
            
            self.blocks.append(WAPKv4Block(
                in_c, out_channels,
                expansion=expansion,
                dilation_rates=dilation_rates,
                drop_path=dpr[i],
                stride=stride,
            ))
    
    def forward(self, x):
        for block in self.blocks:
            x = block(x)
        return x


def test_wapk_v4():
    """æµ‹è¯•WAPK v4æ¨¡å—"""
    RED, GREEN, BLUE, YELLOW, ORANGE, RESET = "\033[91m", "\033[92m", "\033[94m", "\033[93m", "\033[38;5;208m", "\033[0m"
    
    print(GREEN + "="*80 + RESET)
    print(GREEN + " WAPK v4 - é¢‘ç‡è‡ªé€‚åº”+å°ç›®æ ‡å¢å¼º (åŸºäºFADC+StarNet)" + RESET)
    print(GREEN + "="*80 + RESET)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\n{YELLOW}æµ‹è¯•è®¾å¤‡: {device}{RESET}")
    
    # æµ‹è¯•é…ç½®
    batch_size = 2
    in_channels = 64
    out_channels = 64
    height, width = 32, 32
    
    x = torch.randn(batch_size, in_channels, height, width).to(device)
    print(f"\n{BLUE}è¾“å…¥å°ºå¯¸: {x.shape}{RESET}")
    
    # 1. æµ‹è¯•FrequencyAdaptiveDilation
    print(f"\n{ORANGE}[1] æµ‹è¯•FrequencyAdaptiveDilation{RESET}")
    fadc = FrequencyAdaptiveDilation(in_channels, out_channels, dilation_rates=[1,2,3,6]).to(device)
    y_fadc = fadc(x)
    print(f"  è¾“å‡ºå°ºå¯¸: {y_fadc.shape}")
    params_fadc = sum(p.numel() for p in fadc.parameters())
    print(f"  å‚æ•°é‡: {params_fadc:,}")
    
    # 2. æµ‹è¯•StarGate
    print(f"\n{ORANGE}[2] æµ‹è¯•StarGate{RESET}")
    star = StarGate(in_channels, mid_channels=in_channels*2).to(device)
    y_star = star(x)
    print(f"  è¾“å‡ºå°ºå¯¸: {y_star.shape}")
    params_star = sum(p.numel() for p in star.parameters())
    print(f"  å‚æ•°é‡: {params_star:,}")
    
    # 3. æµ‹è¯•WAPKv4Block
    print(f"\n{ORANGE}[3] æµ‹è¯•WAPKv4Block{RESET}")
    wapk_v4 = WAPKv4Block(in_channels, out_channels, expansion=0.5).to(device)
    y_v4 = wapk_v4(x)
    print(f"  è¾“å‡ºå°ºå¯¸: {y_v4.shape}")
    params_v4 = sum(p.numel() for p in wapk_v4.parameters())
    print(f"  å‚æ•°é‡: {params_v4:,}")
    
    # 4. å¯¹æ¯”æ ‡å‡†å·ç§¯
    print(f"\n{BLUE}[4] å‚æ•°é‡å¯¹æ¯”{RESET}")
    standard_params = in_channels * out_channels * 3 * 3
    print(f"  æ ‡å‡†3Ã—3å·ç§¯: {standard_params:,}")
    print(f"  WAPK v4: {params_v4:,} ({params_v4/standard_params*100:.1f}%)")
    print(f"  å¢åŠ : {params_v4-standard_params:,} ({(params_v4-standard_params)/standard_params*100:+.1f}%)")
    
    # 5. æµ‹è¯•WAPKv4Stage
    print(f"\n{ORANGE}[5] æµ‹è¯•WAPKv4Stage{RESET}")
    stage = WAPKv4Stage(in_channels, out_channels, num_blocks=3).to(device)
    y_stage = stage(x)
    print(f"  è¾“å‡ºå°ºå¯¸: {y_stage.shape}")
    params_stage = sum(p.numel() for p in stage.parameters())
    print(f"  å‚æ•°é‡: {params_stage:,}")
    
    print(f"\n{GREEN}{'='*80}{RESET}")
    print(f"{GREEN}WAPK v4 è®¾è®¡æ€»ç»“{RESET}")
    print(f"{GREEN}{'='*80}{RESET}")
    
    print(f"\n{RED}âŒ v1-v3 å¤±è´¥åŸå› :{RESET}")
    print("  1. è¿‡åº¦å…³æ³¨å½¢çŠ¶ (ç«–/æ¨ªå¸¦çŠ¶æ ¸)")
    print("  2. å°éº¦å½¢çŠ¶æ˜¯é™æ€çš„, ä¸èƒ½è§£é‡Š50è½®ååœæ»")
    print("  3. å¿½ç•¥çœŸæ­£ç—›ç‚¹: å°ç›®æ ‡AP_s=0.089, å¯†åº¦å·®å¼‚9.8å€")
    
    print(f"\n{GREEN}âœ… v4 æ ¸å¿ƒæ”¹è¿›:{RESET}")
    print("  [P1ğŸ”´] StarGateè§£å†³å°ç›®æ ‡å¤±æ•ˆ")
    print("    - f1(x)*f2(x) å…ƒç´ çº§é—¨æ§å¢å¼ºå¼±ç‰¹å¾")
    print("    - é›¶é—¨æ§å‚æ•°, æ¢¯åº¦æµç•…, è®­ç»ƒç¨³å®š")
    print("    - ç›®æ ‡: AP_s 0.089 â†’ 0.15+")
    
    print("\n  [P2ğŸ”´] FADCè§£å†³å¯†åº¦æç«¯å·®å¼‚")
    print("    - è‡ªé€‚åº”è†¨èƒ€ç‡ dilation=[1,2,3,6]")
    print("    - å¯†é›†åœºæ™¯(118/å›¾)â†’å¤§æ„Ÿå—é‡(d=6)")
    print("    - ç¨€ç–åœºæ™¯(12/å›¾)â†’å°æ„Ÿå—é‡(d=1)")
    print("    - 9.8å€å¯†åº¦å˜åŒ–â†’åŠ¨æ€é€‚åº”")
    
    print(f"\n{ORANGE}æŠ€æœ¯æ¥æº:{RESET}")
    print("  [CVPR 2024] FADC - Frequency-Adaptive Dilated Convolution")
    print("    è®ºæ–‡: https://arxiv.org/pdf/2403.05369")
    print("  [CVPR 2024] StarNet - Element-wise Feature Gating")
    print("    è®ºæ–‡: https://arxiv.org/pdf/2403.19967")
    
    print(f"\n{GREEN}é¢„æœŸæ•ˆæœ:{RESET}")
    print("  âœ“ å°ç›®æ ‡AP_s: 0.089 â†’ 0.15+ (+70%)")
    print("  âœ“ å¯†åº¦é€‚åº”: 9.8å€èŒƒå›´è‡ªåŠ¨è°ƒèŠ‚æ„Ÿå—é‡")
    print("  âœ“ è®­ç»ƒç¨³å®š: å…¨ç¨‹æ”¶æ•›, æ— 50è½®ååœæ»")
    print("  âœ“ å‚æ•°æ•ˆç‡: <15%å¢åŠ  vs v2çš„+30%")
    
    print(f"\n{BLUE}ä½¿ç”¨å»ºè®®:{RESET}")
    print("  1. æ›¿æ¢backboneæŸä¸€stage: backbone.stage3 = WAPKv4Stage(...)")
    print("  2. æˆ–ä»…æ›¿æ¢decoder: decoder.block = WAPKv4Block(...)")
    print("  3. æ¨èä½ç½®: P3-P5å±‚ (å°ç›®æ ‡+å¯†åº¦é—®é¢˜æœ€ä¸¥é‡)")
    
    print("\n" + "="*80)
    print("âœ“ WAPK v4æ¨¡å—æµ‹è¯•å®Œæˆ")
    print("="*80 + "\n")


if __name__ == '__main__':
    import sys
    
    # è¿è¡Œv4æµ‹è¯•ï¼ˆé»˜è®¤ï¼‰
    if len(sys.argv) == 1 or sys.argv[1] == 'v4':
        test_wapk_v4()
    
    # è¿è¡Œv3æµ‹è¯•ï¼ˆå¯¹æ¯”ï¼‰
    elif sys.argv[1] == 'v3':
        # è®¾ç½®é¢œè‰²è¾“å‡º
        RED, GREEN, BLUE, YELLOW, ORANGE, RESET = "\033[91m", "\033[92m", "\033[94m", "\033[93m", "\033[38;5;208m", "\033[0m"
        
        print(GREEN + "="*80 + RESET)
        print(GREEN + " Wheat-Aware Poly Kernel Network (WAPK) v2 - åŸºäºé¡¶ä¼šä»£ç é‡æ„" + RESET)
        print(GREEN + "="*80 + RESET)
        
        # è¿è¡Œæµ‹è¯•
        test_wapk_module()
    
    # ç‰ˆæœ¬å¯¹æ¯”
    elif sys.argv[1] == 'compare':
        print("\n" + "="*80)
        print("WAPK ç‰ˆæœ¬æ¼”åŒ–å¯¹æ¯”")
        print("="*80)
        print("\nv1 (å¤±è´¥): 4æ¤­åœ†æ ¸ + variance_attn + dual_path â†’ å‚æ•°+40%, 50è½®åå´©æºƒ")
        print("v2 (å¤±è´¥): 3æ¤­åœ†æ ¸ + ç®€åŒ–fusion â†’ å‚æ•°+30%, ä»ç„¶50è½®ååœæ»")
        print("v3 (æç®€): é›¶æ³¨æ„åŠ› + PKIæ®‹å·® â†’ å‚æ•°+8%, ä½†æ€§èƒ½å¹³å¹³")
        print("v4 (é‡æ–°è®¾è®¡): FADC + StarGate â†’ å‚æ•°+15%, é’ˆå¯¹çœŸæ­£ç—›ç‚¹")
        
        print("\næ ¸å¿ƒæ´å¯Ÿ:")
        print("  âŒ å°éº¦å½¢çŠ¶æ˜¯é™æ€ç‰¹å¾ (70% AR 1.5-3.0) â†’ æ¤­åœ†æ ¸æ— æ³•è§£é‡Šè®­ç»ƒåœæ»")
        print("  âœ… å°ç›®æ ‡å¤±æ•ˆ (AP_s=0.089) â†’ StarGateé—¨æ§å¢å¼ºå¼±ç‰¹å¾")
        print("  âœ… å¯†åº¦æç«¯å·®å¼‚ (12-118/å›¾) â†’ FADCè‡ªé€‚åº”æ„Ÿå—é‡")
        print("="*80 + "\n")
    
    else:
        print("Usage: python wapk.py [v4|v3|compare]")
        print("  v4: æµ‹è¯•WAPK v4 (é»˜è®¤)")
        print("  v3: æµ‹è¯•WAPK v3")
        print("  compare: ç‰ˆæœ¬å¯¹æ¯”")

