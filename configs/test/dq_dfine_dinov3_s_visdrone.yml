__include__: [
  'visdrone2019.yml',
  '../runtime.yml',
  '../base/dataloader_dfine.yml',
  '../base/optimizer.yml',
  '../base/dfine_hgnetv2.yml',
]

print_freq: 1600
output_dir: ./outputs/dq_dfine_dinov3_s_visdrone

yolo_metrice: True

postprocessor: DQPostProcessor

DEIM:
  backbone: ConvNeXt
  decoder: DQDFINETransformer

ConvNeXt:
  in_chans: 3
  depths: [3, 3, 9, 3]
  dims: [96, 192, 384, 768]
  pretrained: dinov3_convnext_tiny_pretrain_lvd1689m-21b726bb.pth
  return_idx: [1, 2, 3]

HybridEncoder:
  in_channels: [192, 384, 768]

DQDFINETransformer:
  feat_channels: [256, 256, 256]
  feat_strides: [8, 16, 32]
  hidden_dim: 256
  num_levels: 3

  num_layers: 6
  eval_idx: -1
  num_queries: 300

  num_denoising: 100
  label_noise_ratio: 0.5
  box_noise_scale: 1.0

  # NEW
  reg_max: 32
  reg_scale: 4

  # Auxiliary decoder layers dimension scaling
  # "eg. If num_layers: 6 eval_idx: -4,
  # then layer 3, 4, 5 are auxiliary decoder layers."
  layer_scale: 1  # 2


  num_points: [3, 6, 3] # [4, 4, 4] [3, 6, 3]
  cross_attn_method: default # default, discrete
  query_select_method: default # default, agnostic

  dim_feedforward: 1024

  dynamic_query_list: [300, 500, 900, 1500]
  ccm_cls_num: 4

optimizer:
  type: AdamW
  params: 
    - 
      params: '^(?=.*(?:norm|bn)).*$'     # except bias
      weight_decay: 0.

  lr: 0.0002
  betas: [0.9, 0.999]
  weight_decay: 0.0001


# Increase to search for the optimal ema
epoches: 80 # 120 + 4n

## Our DataAug
train_dataloader: 
  dataset: 
    transforms:
      ops:
        - {type: RandomPhotometricDistort, p: 0.5}
        - {type: RandomZoomOut, fill: 0}
        - {type: RandomIoUCrop, p: 0.8}
        - {type: SanitizeBoundingBoxes, min_size: 1}
        - {type: RandomHorizontalFlip}
        - {type: Resize, size: [640, 640], }
        - {type: SanitizeBoundingBoxes, min_size: 1}
        - {type: ConvertPILImage, dtype: 'float32', scale: True, dinov3_norm: True}   
        - {type: ConvertBoxes, fmt: 'cxcywh', normalize: True}
      policy:
        epoch: 72   # list 
  collate_fn:
    stop_epoch: 72
    ema_restart_decay: 0.9999
    base_size_repeat: 4
  total_batch_size: 4
val_dataloader:
  dataset:
    transforms:
      ops:
        - {type: Resize, size: [640, 640], }
        - {type: ConvertPILImage, dtype: 'float32', scale: True, dinov3_norm: True}
  total_batch_size: 4

DEIMCriterion:
  weight_dict: {loss_vfl: 1, loss_bbox: 5, loss_giou: 2, loss_fgl: 0.15, loss_ddf: 1.5, loss_cardinality: 1, loss_ccm: 1}
  losses: ['vfl', 'boxes', 'local', 'cardinality', 'ccm']
  ccm_params: [10, 100, 500]