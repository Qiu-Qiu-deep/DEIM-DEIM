print_freq: 457

comment: ""

model: DEIM_MG

clip_max_norm: 0.1
# Add, default for step lr scheduler 
lrsheduler: flatcosine
lr_gamma: 0.5
warmup_iter: 500
flat_epoch: 40
no_aug_epoch: 4

optimizer:
  type: AdamW
  params:
    -
      params: '^(?=.*backbone)(?!.*norm|bn).*$'
      lr: 0.0006
    -
      params: '^(?=.*backbone)(?=.*norm|bn).*$'
      lr: 0.0006
      weight_decay: 0.
    -
      params: '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn|bias)).*$'
      weight_decay: 0.

  lr: 0.0008
  betas: [0.9, 0.999]
  weight_decay: 0.0001

# Increase to search for the optimal ema
epoches: 72
train_dataloader:
  dataset:
    transforms:
      policy:
        epoch: 52
  collate_fn:
    stop_epoch: 52
    ema_restart_decay: 0.9999
    base_size_repeat: ~

train_dataloader:
  total_batch_size: 8
val_dataloader:
  total_batch_size: 8