
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Method}
\label{sec:method}

\subsection{Preliminaries}
\paragraph{O2M vs. O2O.} The O2M assignment strategy~\cite{zheng2021yolox, feng2021tood} is widely adopted in traditional object detectors, and its supervision can be formulated as follows:
\begin{equation} 
\text{loss} = \sum_{i=0}^N\sum_{j=0}^{M_{i}} f(\hat{y}_{ij}, y_{i}),\label{eq:assign} 
\end{equation}
where $N$ is the total number of targets, $M_{i}$ is the number of matches for the $i$-th target, $\hat{y}_{ij}$ represents the $j$-th match for the $i$-th target, $y_{i}$ denotes the $i$-th ground-truth label, and $f$ is the loss function. O2M enhances supervision by increasing $M_{i}$, i.e., assigning multiple queries to each target ($M_{i} > 1$) and thus providing dense supervision, as illustrated in Fig.~\ref{fig:toy_O2M}. In contrast, the O2O assignment only pairs each target with a single best prediction, determined via the Hungarian algorithm, which minimizes a cost function balancing classification and localization errors (Fig.~\ref{fig:toy_O2O}). O2O can be considered a special case of O2M where $M_{i} = 1$ for all targets.

\paragraph{Focal loss.}
Focal loss (FL)~\cite{lin2017focal} was introduced to prevent an abundance of easy negatives from overwhelming the detector during training, directing focus instead towards a sparse set of hard examples. It serves as the default classification loss in DETRs~\cite{zhu2020deformable, zhang2022dino} and is defined as follows:
\begin{equation}
\label{eq:fl}
\text{FL}(p, y) = 
\begin{cases} 
  -\alpha (1 - p)^\gamma \log(p)  & y = 1 \\
  -(1 - \alpha) p^\gamma \log(1 - p) & y = 0,
\end{cases}
\end{equation}
where $y \in \{0, 1\} $ specifies the ground-truth class and $p \in [0, 1] $ represents the predicted probability for the foreground class. The parameter $\gamma$ controls the balance between easy and hard samples, while $\alpha$ adjusts the weighting between foreground and background classes. In the FL, only the sampleâ€™s class and confidence are considered, with no attention given to bounding box quality, i.e., localization.


% \xiaodong{should we introduce some background and overview of the following method?}
 
% \subsection
% \noindent

\begin{figure}[t]
    \centering
    \small
    \setlength{\abovecaptionskip}{0.cm}
    \setlength{\belowcaptionskip}{-0.cm}

    \hfill
    % \hspace{-0.8cm}
    \begin{subfigure}{0.24\textwidth}
        \includegraphics[width=\textwidth]{figs/one_and_many.pdf}
        \caption{Matching distribution}
        \label{fig:num_match}
    \end{subfigure}
    \hfill
    \hspace{-0.2cm}
    \begin{subfigure}{0.24\textwidth}
        \includegraphics[width=\textwidth]{figs/one_vs_many.pdf}
        \caption{Ratios between O2M and O2O}
        \label{fig:ratio_match}
    \end{subfigure}
    \hfill
    \vspace{-0.2cm}
    \caption{\textbf{Anchor/Query Match Comparison}. Comparison of the number of matched anchors/queries per image in one COCO epoch using one-to-many (SimOTA~\cite{zheng2021yolox}) and one-to-one (Hungarian~\cite{carion2020end}) matching schemes.}
    \label{fig:many-vs-one}
\vspace{-0.4cm}
\end{figure}

\subsection{Improving matching efficiency: Dense O2O}


The one-to-one (O2O) matching scheme, commonly used in DETR-based models, matches each target to only one predicted query. This approach, implemented via the Hungarian algorithm~\cite{kuhn1955hungarian}, allows for end-to-end training and eliminates the need for NMS. However, a key limitation of O2O is that it generates significantly fewer positive samples compared to traditional one-to-many (O2M) methods like SimOTA~\cite{zheng2021yolox}. This leads to sparse supervision, which can slow down convergence during training.

To better understand this issue, we trained RT-DETRv2~\cite{lv2024rt} with a ResNet50 backbone on the MS COCO dataset~\cite{lin2014microsoft}. We compared the number of positive matches generated by both Hungarian (O2O) and SimOTA (O2M) strategies. As shown in Fig.~\ref{fig:num_match}, O2O produces a sharp peak under 10 positive matches per image, while O2M generates a broader distribution with many more positive matches, sometimes exceeding 80 positive samples for a single image. Fig.~\ref{fig:ratio_match} further highlights that SimOTA generates about 10 times as many matches as O2O in extreme cases. This demonstrates that O2O has fewer positive matches, potentially slowing down optimization.

We propose \textbf{Dense O2O} as an efficient alternative. This strategy retains the one-to-one matching structure of O2O (with $M_i = 1$), but increases the number of targets ($N$) per image, achieving denser supervision. For example, as shown in Fig.~\ref{fig:toy_Dense_O2O}, we replicate the original image into four quadrants and combine them into a single composite image, maintaining the original image dimensions. This increases the number of targets from 1 to 4, boosting the supervision level in Eq.~\ref{eq:assign} while keeping the matching structure unchanged. Dense O2O achieves a level of supervision comparable to O2M but without the added complexity and computational overhead.

\subsection{Improving matching quality: Matchability-Aware Loss}

\paragraph{Limitations of VFL.}  
The VariFocal Loss (VFL)~\cite{zhang2021varifocalnet}, built on the FL~\cite{lin2017focal}, has been shown to improve object detection performance, especially in DETR models~\cite{zhao2024detrs, lv2024rt, cai2023align}. VFL loss is expressed as :
\begin{equation}
\label{eq:vfl}
\small
\text{VFL}(p, q, y) = 
\begin{cases} 
  -q(q\log(p) + (1 - q)\log(1 - p)) &  q > 0 \\
  -\alpha p^\gamma \log(1 - p) & q = 0,
\end{cases}
\end{equation}
where $q$ denotes the IoU between the predicted bounding box and its target box. For foreground samples ($q>0$), the target label is set to $q$, while background samples ($q$ = 0) have a target label of 0. VFL incorporates the IoU to improve the quality of queries in DETR~\cite{zhao2024detrs}. 

However, VFL has two key limitations when optimizing low-quality matches:  
i). \textit{Low-Quality Matches}. VFL focuses mainly on high-quality matches (high IoU). For low-quality matches (low IoU), the loss remains small, preventing the model from refining predictions for low-quality boxes. For low-quality matching (with low IoU, e.g., Fig.~\ref{fig:toy_lowquality}), however, the loss remains minimal (marked by a \textcolor{red}{$\star$} in Fig.~\ref{fig:lossscape_vfl}). ii) \textit{Negative Samples}. VFL treats matches with no overlap as negative samples, which reduces the number of positive samples and limits effective training.

These issues are less problematic for traditional detectors due to their dense anchors and one-to-many assignment strategies. However, in the DETR framework, where queries are sparse and matching is more rigid, these limitations become more pronounced.

\paragraph{Matchability-Aware Loss.}  
To address these issues, we propose the Matchability-Aware Loss (\ourclsloss), which extends the benefits of VFL while mitigating its shortcomings. \ourclsloss\ incorporates the matching quality directly into the loss function, making it more sensitive to low-quality matches. The formula for \ourclsloss\ is:
\begin{equation}
\label{eq:xfl}
\small
\text{\ourclsloss}(p, q, y) = 
\begin{cases} 
  -q^\gamma \log(p) - (1 - q^\gamma)\log(1 - p) &  y=1 \\
  -p^\gamma \log(1 - p) & y = 0.
\end{cases}
\end{equation}

Compared to VFL, we introduce several small but
important changes. Specifically, the target label has been modified from $q$ to $q^\gamma$, simplifying the loss weights for positive and negative samples and removing the hyperparameter $\alpha$ used to balance positive and negative samples. This change helps to avoid the overemphasis on high-quality boxes and improves the overall training process. This can be easily seen from the loss landscape between VFL (in Fig.~\ref{fig:lossscape_vfl}) and \ourclsloss\ (in Fig.~\ref{fig:lossscape_ours}). Note that the impact of $\gamma$ is provided in Section~\ref{sec_discuss}.

\paragraph{Comparison with VFL.}  
We compare \ourclsloss\ and VFL in handling both low-quality and high-quality matches. In the case of low-quality matches (IoU = 0.05, in Fig.~\ref{fig:low_quality}), \ourclsloss\ shows a sharper increase in loss as predicted confidence grows, compared to VFL, which remains almost unchanged. For high-quality matches (IoU = 0.95, in Fig.~\ref{fig:high_quality}), both \ourclsloss\ and VFL perform similarly, confirming that \ourclsloss\ improves training efficiency without compromising the performance on high-quality matches.


\begin{figure}[t]
    \centering
    \small
    \setlength{\abovecaptionskip}{0.cm}
    \setlength{\belowcaptionskip}{-0.cm}
    \hfill
    \begin{subfigure}{0.235\textwidth}
        \includegraphics[width=\textwidth]{figs/2d_losses_1.5_0.75_0.05.png}
        \caption{\textbf{Low quality}: IoU = 0.05}
        \label{fig:low_quality}
    \end{subfigure}
    \hfill 
    \begin{subfigure}{0.235\textwidth}
        \includegraphics[width=\textwidth]{figs/2d_losses_1.5_0.75_0.95.png}
        \caption{\textbf{High quality}: IoU = 0.95}
        \label{fig:high_quality}
    \end{subfigure}
    \hfill
    \vspace{-0.1cm}
   \caption{\textbf{VFL vs. \ourclsloss\ Comparison.} Comparison of VFL and our \ourclsloss\ for low-quality (IoU = 0.05, Fig.~\ref{fig:low_quality}) and high-quality (IoU = 0.95, Fig.~\ref{fig:high_quality}) matching cases.}
    \label{fig:loss_case}
\vspace{-0.4cm}
\end{figure}
