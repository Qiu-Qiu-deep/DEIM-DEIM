% \section{Introduction}


% The demand for real-time object detection has been increasing across various applications, including autonomous driving, robotics, and video surveillance~\citep{arani2022comprehensive}. Among the most influential real-time detectors are the YOLO series~\citep{redmon2016you, NEURIPS2023_a0673542, redmon2018yolov3,bochkovskiy2020yolov4,yolov5v7.0,li2023yolov6v3,ge2021yolox,wang2023yolov7,yolov8, wang2024yolov9}, widely recognized for their efficiency and robust community ecosystem. However, YOLO detectors often rely on Non-Maximum Suppression (NMS) for post-processing, which not only slows down inference but also introduces hyperparameters that can destabilize both speed and accuracy.


% The introduction of the Detection Transformer (DETR)~\citep{carion2020end} marked a significant breakthrough in object detection by introducing a fully end-to-end architecture. Despite its strong performance~\citep{carion2020end,sun2021sparse,zhu2020deformable,meng2021conditional,wang2022anchor,liu2021dab,li2022dn,zhang2022dino}, traditional DETR models are hindered by high latency and computational demands, making them unsuitable for real-time applications. RT-DETR~\citep{lv2023detrs} addresses these challenges by developing a real-time variant of DETR, offering an end-to-end alternative to YOLO detectors and outperforming them in certain metrics. Concurrently, YOLOv10~\citep{wang2024yolov10} eliminates the need for NMS, achieving significant speed improvements and surpassing RT-DETR in the latency-accuracy trade-off. However, LW-DETR~\citep{chen2024lw} has demonstrated that DETR architectures can achieve higher performance ceilings than the YOLO series, especially when trained on large-scale datasets like Objects365~\citep{shao2019objects365}.

% Despite these advancements, a persistent issue across many current detectors is the design of the regression task itself. The latest detectors still rely on vanilla bounding box regression based on predicting Dirac delta distribution~\citep{yolov1,SSD,fasterrcnn,FCOS}, failing to accurately capture the localization uncertainty. While some approaches have introduced probability distributions to better describe these boxes~\citep{softernms,gaussian_yolov3,gfocal,offsetbin,gfocalv2}, these methods are still constrained by their reliance on anchor-based frameworks, limiting their compatibility with modern, anchor-free detectors like YOLOX~\citep{ge2021yolox} and DETR~\citep{carion2020end}. Furthermore, their one-shot prediction design often lacks effective regression refinement, which hinders their ability to achieve more accurate predictions.

% In this work, we propose D-FINE, a powerful real-time object detector that excels in localization precision by redefining the bounding box regression task in DETR models. D-FINE consists of two key components: Fine-grained Distribution Refinement (FDR) and Global Optimal Localization Self-Distillation (GO-LSD). FDR transforms the regression process from predicting fixed coordinates to iteratively refining fine-grained probability distributions, significantly improving bounding box accuracy. GO-LSD is a bidirectional optimization strategy that enhances earlier layers by efficiently learning from its own refined predictions, improving performance without increasing computational overhead. As shown in \Cref{fig:latency} D-FINE surpasses RT-DETR by 0.8\% AP on the COCO real-time object detection benchmark~\citep{COCO} while achieving lower latency, smaller model size, and reduced computational cost, setting a new standard in the field. After pretraining D-FINE on Objects365~\citep{shao2019objects365}, the D-FINE series achieves up to 58.8\% AP on COCO, positioning them as the highest-performing models in this comparison. This achievement underscores the importance of our contributions in pushing DETR models beyond their previous limitations. Additionally, leveraging plug-and-play modules FDR and GO-LSD modules, the performances of existing DETR models are consistently boosted by up to 5.3\% AP.

% In conclusion, D-FINE not only expands the performance ceiling of DETR models but also acts as the most formidable competitor to the YOLO series. By addressing key challenges in bounding box regression and localization, we hope this approach offers a meaningful step forward for object detection and inspires further exploration in the field.

\section{Introduction}

% The demand for real-time object detection has been increasing across various applications~\citep{arani2022comprehensive}. Among the most influential real-time detectors are the YOLO series~\citep{li2023yolov6v3, NEURIPS2023_a0673542, wang2023yolov7, yolov8, wang2024yolov9}, widely recognized for their efficiency and robust community ecosystem. However, YOLO detectors often rely on Non-Maximum Suppression (NMS) for post-processing, which not only slows down inference but also introduces hyperparameters that can destabilize both speed and accuracy. 

% The introduction of the Detection Transformer (DETR)~\citep{carion2020end} marked a significant breakthrough in object detection by eliminating the need for NMS and anchor boxes. Despite its strong performance~\citep{zhu2020deformable, wang2022anchor, liu2021dab, li2022dn, zhang2022dino}, traditional DETR models are hindered by high latency and computational demands. RT-DETR~\citep{lv2023detrs} addresses these challenges by developing a real-time variant of DETR, offering an end-to-end alternative to YOLO detectors. Concurrently, YOLOv10~\citep{wang2024yolov10} eliminates the need for NMS, achieving significant speed improvements and surpassing RT-DETR in the speed-accuracy trade-off. However, LW-DETR~\citep{chen2024lw} has demonstrated that DETR architectures can achieve higher performance ceilings than the YOLO series, especially when trained on large-scale datasets like Objects365~\citep{shao2019objects365}.

% The demand for real-time object detection continues to grow across various applications~\citep{arani2022comprehensive}. Among the most influential detectors are the YOLO series~\citep{li2023yolov6v3, NEURIPS2023_a0673542, wang2023yolov7, yolov8, wang2024yolov9}, widely recognized for their efficiency and strong community support. Recently, YOLOv10~\citep{wang2024yolov10} eliminated the need for Non-Maximum Suppression (NMS), making the model fully end-to-end and significantly reducing inference time. As a strong competitor, the Detection Transformer (DETR)~\citep{carion2020end} offers distinct advantages, including transformer-based global context modeling and direct set prediction without anchor boxes. While DETR models have shown exceptional performance, traditional versions are often limited by high latency and computational demands~\citep{zhu2020deformable, wang2022anchor, liu2021dab, li2022dn, zhang2022dino}. RT-DETR~\citep{lv2023detrs} addresses these limitations by introducing a real-time variant, offering a robust end-to-end alternative to YOLO detectors. Additionally, LW-DETR~\citep{chen2024lw} demonstrates that DETR architectures can surpass the performance ceilings of the YOLO series, particularly when trained on large-scale datasets like Objects365~\citep{shao2019objects365}. Thus, despite YOLOv10's success in achieving end-to-end detection, DETR retains its value for its superior scalability and potential to excel in more complex detection scenarios.
% Recently, YOLOv10~\citep{wang2024yolov10} eliminates the need for Non-Maximum Suppression (NMS), making YOLO end-to-end and significantly speeding up inference.

The demand for real-time object detection has been increasing across various applications~\citep{arani2022comprehensive}. Among the most influential real-time detectors are the YOLO series~\citep{redmon2016you, NEURIPS2023_a0673542, wang2023yolov7, yolov8, wang2024yolov9, wang2024yolov10, yolo11}, widely recognized for their efficiency and robust community ecosystem. As a strong competitor, the Detection Transformer (DETR)~\citep{carion2020end, zhu2020deformable, liu2021dab, li2022dn, zhang2022dino} offers distinct advantages due to its transformer-based architecture, which allows for global context modeling and direct set prediction without reliance on Non-Maximum Suppression (NMS) and anchor boxes. However, they are often hindered by high latency and computational demands~\citep{zhu2020deformable, liu2021dab, li2022dn, zhang2022dino}. RT-DETR~\citep{lv2023detrs} addresses these limitations by developing a real-time variant, offering an end-to-end alternative to YOLO detectors. Moreover, LW-DETR~\citep{chen2024lw} has shown that DETR can achieve higher performance ceilings than YOLO, especially when trained on large-scale datasets like Objects365~\citep{shao2019objects365}. 

% Therefore, even though YOLOv10 has achieved end-to-end detection, DETR remains valuable due to its superior scalability and potential for higher performance in complex detection tasks.
% This approach, while straightforward, has several limitations. By treating bounding box edges as precise values, i
 % Additionally, directly regressing numerical values, rather than using a fine-grained intermediate representation, increases the risk of significant localization errors, especially in ambiguous scenarios where small prediction shifts can cause substantial misalignments.

Despite the substantial progress made in real-time object detection, several unresolved issues continue to limit the performance of detectors. One key challenge is the formulation of bounding box regression. Most detectors predict bounding boxes by regressing fixed coordinates, treating edges as precise values modeled by Dirac delta distributions~\citep{SSD, fasterrcnn, FCOS, Lyu2022RTMDetAE}. While straightforward, this approach fails to model localization uncertainty. Consequently, models are constrained to use L1 loss and IoU loss, which provide insufficient guidance for adjusting each edge independently~\citep{girshick2015fast}. This makes the optimization process sensitive to small coordinate changes, leading to slow convergence and suboptimal performance. Although methods like GFocal~\citep{gfocal, gfocalv2} address uncertainty through probability distributions, they remain limited by anchor dependency, coarse localization, and lack of iterative refinement. Another challenge lies in maximizing the efficiency of real-time detectors, which are constrained by limited computation and parameter budgets to maintain speed. Knowledge distillation (KD) is a promising solution, transferring knowledge from larger teachers to smaller students to improve performance without increasing costs~\citep{hinton2015distilling}. However, traditional KD methods like Logit Mimicking and Feature Imitation have proven inefficient for detection tasks and can even cause performance drops in state-of-the-art models~\citep{zheng2022localization}. In contrast, localization distillation (LD) has shown better results for detection. Nevertheless, integrating LD remains challenging due to its substantial training overhead and incompatibility with anchor-free detectors.

% Another challenge lies in maximizing the efficiency of real-time detectors, which are constrained by limited computation and parameter budgets to maintain speed. Knowledge distillation (KD) is well-suited for this purpose, as it transfers knowledge from larger teachers to smaller students~\citep{hinton2015distilling}, improving performance without increasing computational costs and parameters. 
% However, traditional distillation methods like Logit Mimicking~\citep{Zagoruyko2017AT,TA,DenselyTA} and Feature Imitation~\citep{FitNets} are often inefficient for detection tasks and can even lead to performance drops when applied to state-of-the-art models. The recent approach indicates localization distillation (LD) is significantly more effective~\citep{zheng2022localization}. Nevertheless, integrating LD remains challenging due to its substantial training overhead and incompatibility with anchor-free detectors.


To address these issues, we propose \textbf{D-FINE}, a novel real-time object detector that redefines bounding box regression and introduces an effective self-distillation strategy. Our approach tackles the problems of difficult optimization in fixed-coordinate regression, the inability to model localization uncertainty, and the need for effective distillation with less training cost. We introduce \textbf{Fine-grained Distribution Refinement (FDR)} to transform bounding box regression from predicting fixed coordinates to modeling probability distributions, providing a more fine-grained intermediate representation. FDR refines these distributions iteratively in a residual manner, allowing for progressively finer adjustments and improving localization precision. Recognizing that deeper layers produce more accurate predictions by capturing richer localization information within their probability distributions, we introduce \textbf{Global Optimal Localization Self-Distillation (GO-LSD)}. GO-LSD transfers localization knowledge from deeper layers to shallower ones with negligible extra training cost. By aligning shallower layers' predictions with refined outputs from later layers, the model learns to produce better early adjustments, accelerating convergence and improving overall performance. Furthermore, we streamline computationally intensive modules and operations in existing real-time DETR architectures~\citep{lv2023detrs, chen2024lw}, making D-FINE faster and more lightweight. While such modifications typically result in performance loss, FDR and GO-LSD effectively mitigate this degradation, achieving a better balance between speed and accuracy.

Experimental results on the COCO dataset~\citep{COCO} demonstrate that D-FINE achieves state-of-the-art performance in real-time object detection, surpassing existing models in accuracy and efficiency. D-FINE-L and D-FINE-X achieve 54.0\% and 55.8\% AP, respectively on COCO \texttt{val2017}, running at 124 FPS and 78 FPS on an NVIDIA T4 GPU. After pretraining on larger datasets like Objects365~\citep{shao2019objects365}, the D-FINE series attains up to 59.3\% AP, surpassing all existing real-time detectors, showcasing both scalability and robustness. Moreover, our method enhances a variety of DETR models by up to 5.3\% AP with negligible extra parameters and training costs, demonstrating its flexibility and generalizability. In conclusion, D-FINE pushes the performance boundaries of real-time detectors. By addressing key challenges in bounding box regression and distillation efficiency through FDR and GO-LSD, we offer a meaningful step forward in object detection, inspiring further exploration in the field.
