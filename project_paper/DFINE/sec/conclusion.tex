\section{Conclusion}
% In this paper, we introduce D-FINE, a novel real-time object detector that integrates Fine-grained Distribution Refinement (FDR) and Global Optimal Localization Self-Distillation (GO-LSD). FDR enhances localization precision by transforming the regression process from predicting fixed coordinates to iteratively refining probability distributions, providing a fine-grained intermediate representation for more precise adjustments. GO-LSD transfers localization knowledge from refined predictions into earlier layers, improving overall accuracy without additional computational costs. Experimental results on COCO and Objects365 demonstrate that D-FINE achieves state-of-the-art accuracy and efficiency in real-time object detection. 
In this paper, we introduce D-FINE, a powerful real-time object detector that redefines the bounding box regression task in DETR models through Fine-grained Distribution Refinement (FDR) and Global Optimal Localization Self-Distillation (GO-LSD). Experimental results on the COCO dataset demonstrate that D-FINE achieves state-of-the-art accuracy and efficiency, surpassing all existing real-time detectors. 
\textbf{Limitation and Future Work:} However, the performance gap between lighter D-FINE models and other compact models remains small. One possible reason is that shallow decoder layers may yield less accurate final-layer predictions, limiting the effectiveness of distilling localization knowledge into earlier layers. Addressing this challenge necessitates enhancing the localization capabilities of lighter models without increasing inference latency. Future research could investigate advanced architectural designs or novel training paradigms that allow for the inclusion of additional sophisticated decoder layers during training while maintaining lightweight inference by simply discarding them at test time. We hope D-FINE inspires further advancements in this area.




% To address this, future work could explore enhance the localization capabilities of shallow models without significantly increasing computational complexity.



% integrating more complex decoder layers on top of the existing architecture during training, leveraging GO-LSD to enhance the localization capabilities of shallow layers. By discarding these deeper layers during inference, we maintain lightweight performance while the shallow layers retain the distilled localization knowledge, improving overall accuracy.

% In conclusion, D-FINE not only achieves excelling performance but also opens several avenues for further research. We hope D-FINE inspires further advancements in this area.


% We hope D-FINE inspires further advancements in this area.




% However, D-FINE is still limited by the inherent memory I/O overhead of the DETR architecture, which may affect real-time performance gains despite reductions in computational complexity. Despite this, D-FINE opens several avenues for further research, such as integrating more complex decoders during training to refine localization, while keeping inference lightweight. We hope D-FINE encourages further exploration.

% One potential direction is to expand the decoder with more complex layers during training to enhance localization precision. Once the model has distilled this additional knowledge, the complex decoder could be discarded during inference, preserving the lightweight nature of the detector while benefiting from the improved accuracy gained during training. 
