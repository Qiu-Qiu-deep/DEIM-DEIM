% \begin{figure}[h]
%     \centering
%     \begin{minipage}[b]{0.328\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{fig/latency.png}
%     \end{minipage}
%     \begin{minipage}[b]{0.328\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{fig/params.png}
%     \end{minipage}
%     \begin{minipage}[b]{0.328\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{fig/flops.png}
%     \end{minipage}
%     \caption{Comparisons with other detectors in terms of latency (left), model size (mid), and computational cost (right). We measure end-to-end latency using TensorRT FP16 on an NVIDIA T4 GPU.}
%     \label{fig:latency}
%     % \vspace{-4pt}
% \end{figure}

\begin{figure}[h]
    \centering

    \includegraphics[width=0.99\textwidth]{fig/stats.png}

    \caption{Comparisons with other detectors in terms of latency (left), model size (mid), and computational cost (right). We measure end-to-end latency using TensorRT FP16 on an NVIDIA T4 GPU.}
    \label{fig:latency}
    % \vspace{-4pt}
\end{figure}

% \begin{abstract}

% In this work, we introduce a novel paradigm that thoroughly redefines the bounding box regression task in DETR, focusing on fine-grained localization.  Our method implements a fine-grained distribution refinement strategy for accurate bounding box regression. Additionally, we propose the decoupled Global Optimal Localization Self-Distillation, allowing the model to learn more effectively from its optimal predictions without adding computational overhead. Building on these plug-and-play methods, we elevate the performance of the entire DETR series by $X.X\%-X.X\%$ on COCO. We also develop a state-of-the-art detector D-FINE, which achieves $54.0\%$ AP on COCO and $260$ FPS on RTX 3090 GPU. After pre-training with Objects365, D-FINE achieves $XX.X\%$ AP, surpassing all other real-time detectors. The code will be released soon.
% \end{abstract}

% \begin{abstract}

% In this work, we redefine the bounding box regression task in DETR by focusing on more fine-grained localization. Our approach introduces a Fine-grained Distribution Refinement (FDR) strategy that significantly enhances the precision of bounding box predictions. Additionally, we present a Global Optimal Localization Self-Distillation (GO-LSD) technique, enabling the model to leverage its most accurate distribution predictions for self-improvement, without additional computational costs. These plug-and-play methods significantly boost the performance of various DETR models, achieving improvements of $X.X\%-X.X\%$ on the MS-COCO dataset. We further develop D-FINE, a state-of-the-art real-time end-to-end detector, which reaches $54.0\%$ AP on MS-COCO and runs at 260 FPS on an RTX 3090 GPU. After pre-training on Objects365, D-FINE achieves $XX.X\%$ AP, outperforming all existing real-time detectors. The code and models will be made publicly available.



% \end{abstract}

\begin{abstract}


We introduce \textbf{D-FINE}, a powerful real-time object detector that achieves outstanding localization precision by redefining the bounding box regression task in DETR models. D-FINE comprises two key components: \textbf{Fine-grained Distribution Refinement (FDR)} and \textbf{Global Optimal Localization Self-Distillation (GO-LSD)}. FDR transforms the regression process from predicting fixed coordinates to iteratively refining probability distributions, providing a fine-grained intermediate representation that significantly enhances localization accuracy. GO-LSD is a bidirectional optimization strategy that transfers localization knowledge from refined distributions to shallower layers through self-distillation, while also simplifying the residual prediction tasks for deeper layers. Additionally, D-FINE incorporates lightweight optimizations in computationally intensive modules and operations, achieving a better balance between speed and accuracy. Specifically, D-FINE-L\,/\,X achieves 54.0\%\,/\,55.8\% AP on the COCO dataset at 124\,/\,78 FPS on an NVIDIA T4 GPU. When pretrained on Objects365, D-FINE-L\,/\,X attains 57.1\%\,/\,59.3\% AP, surpassing all existing real-time detectors. Furthermore, our method significantly enhances the performance of a wide range of DETR models by up to 5.3\% AP with negligible extra parameters and training costs. Our code and pretrained models: \url{https://github.com/Peterande/D-FINE}.




% We introduce \textbf{D-FINE}, a powerful real-time object detector that achieves outstanding localization precision by redefining the bounding box regression task in DETR models. D-FINE comprises two key components: \textbf{Fine-grained Distribution Refinement (FDR)} and \textbf{Global Optimal Localization Self-Distillation (GO-LSD)}. FDR transforms the regression process from predicting fixed coordinates to iteratively refining probability distributions, which serve as a fine-grained intermediate representation, significantly enhancing localization accuracy. GO-LSD is a bidirectional optimization strategy that utilizes the model's own refined distributions to enhance earlier layers through self-distillation, while simplifying the prediction task for subsequent layers. Additionally, D-FINE incorporates lightweight optimizations in computationally intensive modules and operations, achieving a better balance between speed and accuracy. Specifically, D-FINE-L\,/\,X achieves 54.0\%\,/\,55.8\% AP on the COCO dataset at 124\,/\,78 FPS on an NVIDIA T4 GPU. When pretrained on Objects365, D-FINE-L\,/\,X attains 56.9\%\,/\,59.0\% AP, surpassing all existing real-time detectors. Furthermore, our method significantly enhances the performance of a wide range of DETR models by up to 5.3\% AP with negligible extra parameters and training costs. Our code and models will be made publicly available. 

\end{abstract}
